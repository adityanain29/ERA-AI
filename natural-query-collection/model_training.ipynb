{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51368f29-3fdf-4e6c-be12-82e0bbaeee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a309f24-1aac-43ad-9e92-08eccef2715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df0_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b803dce-c0c7-4050-8fe7-4c3ab5a7fbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what be effect acquisition PG 's cash flow inv...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[ 2.14685693e-01 -2.64935166e-01 -9.67863977e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what be advantage use price oscillator sny ide...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[-4.54222262e-01 -3.89720380e-01 -1.31479466e+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assess use high-low index amgen inc. s trade d...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[-5.93504727e-01  3.32001328e-01 -8.57228637e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what be psychological factor contribute fluctu...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[-5.01789868e-01  1.82305619e-01 -8.64736974e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what be implication use ulcer index citi measu...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>[-1.86315421e-02  2.10510954e-01 -1.39836431e+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class  \\\n",
       "0  what be effect acquisition PG 's cash flow inv...  relevant   \n",
       "1  what be advantage use price oscillator sny ide...  relevant   \n",
       "2  assess use high-low index amgen inc. s trade d...  relevant   \n",
       "3  what be psychological factor contribute fluctu...  relevant   \n",
       "4  what be implication use ulcer index citi measu...  relevant   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [ 2.14685693e-01 -2.64935166e-01 -9.67863977e-...  \n",
       "1  [-4.54222262e-01 -3.89720380e-01 -1.31479466e+...  \n",
       "2  [-5.93504727e-01  3.32001328e-01 -8.57228637e-...  \n",
       "3  [-5.01789868e-01  1.82305619e-01 -8.64736974e-...  \n",
       "4  [-1.86315421e-02  2.10510954e-01 -1.39836431e+...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03faf42c-5877-4d41-937c-8a36baaa3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4868d2be-c5db-44a4-803e-68292f8a8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the model\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return self.softmax(out)\n",
    "\n",
    "# Convert embedding strings to arrays\n",
    "def convert_to_array(embedding_str):\n",
    "    embedding_list = embedding_str.replace('[', '').replace(']', '').split()\n",
    "    return np.array(embedding_list, dtype=float)\n",
    "\n",
    "df['embeddings'] = df['embeddings'].apply(convert_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ea3644a-7d37-4cfa-9beb-fc782bdfb87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca6cdce-33f8-44a9-b950-f56d43a97298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for embeddings, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            try:\n",
    "                outputs = model(embeddings)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during training: {e} | Embeddings shape: {embeddings.shape} | Labels shape: {labels.shape}\")\n",
    "        logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate model function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            try:\n",
    "                outputs = model(embeddings)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during evaluation: {e} | Embeddings shape: {embeddings.shape} | Labels shape: {labels.shape}\")\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f7a68b-f0ea-487b-a543-5e9d816e4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_int('hidden_size', 64, 256)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 5, 20)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
    "\n",
    "    X = np.array(df['embeddings'].tolist())\n",
    "    y = np.array(df['class_encoded'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = len(np.unique(y_train))\n",
    "\n",
    "    model = EmbeddingClassifier(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
    "    accuracy = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57eef22b-ec4a-4cb6-b620-004c250fdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-26 16:06:15,459] A new study created in memory with name: no-name-757ef027-347b-4c3b-b55e-38f4fbb18245\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 857.83it/s]\n",
      "2024-09-26 16:06:16,646 - INFO - Epoch [1/7], Loss: 0.314111991152905\n",
      "Epoch 2/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 942.73it/s]\n",
      "2024-09-26 16:06:17,182 - INFO - Epoch [2/7], Loss: 0.31326186969728753\n",
      "Epoch 3/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 933.88it/s]\n",
      "2024-09-26 16:06:17,725 - INFO - Epoch [3/7], Loss: 0.31326186934320055\n",
      "Epoch 4/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 935.73it/s]\n",
      "2024-09-26 16:06:18,266 - INFO - Epoch [4/7], Loss: 0.31326186893009905\n",
      "Epoch 5/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 937.39it/s]\n",
      "2024-09-26 16:06:18,806 - INFO - Epoch [5/7], Loss: 0.31326186851699755\n",
      "Epoch 6/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 924.83it/s]\n",
      "2024-09-26 16:06:19,354 - INFO - Epoch [6/7], Loss: 0.3132618681629105\n",
      "Epoch 7/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 872.61it/s]\n",
      "2024-09-26 16:06:19,934 - INFO - Epoch [7/7], Loss: 0.31326186780882354\n",
      "Evaluating: 100%|███████████████████████████| 127/127 [00:00<00:00, 1884.45it/s]\n",
      "[I 2024-09-26 16:06:20,038] Trial 0 finished with value: 100.0 and parameters: {'hidden_size': 225, 'learning_rate': 0.0031717893605886192, 'batch_size': 62, 'num_epochs': 7}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1059.23it/s]\n",
      "2024-09-26 16:06:21,305 - INFO - Epoch [1/8], Loss: 0.3141648866381103\n",
      "Epoch 2/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1066.56it/s]\n",
      "2024-09-26 16:06:22,223 - INFO - Epoch [2/8], Loss: 0.3132619006423892\n",
      "Epoch 3/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1026.81it/s]\n",
      "2024-09-26 16:06:23,176 - INFO - Epoch [3/8], Loss: 0.3132618980190527\n",
      "Epoch 4/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1039.12it/s]\n",
      "2024-09-26 16:06:24,118 - INFO - Epoch [4/8], Loss: 0.31326189713443925\n",
      "Epoch 5/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1096.65it/s]\n",
      "2024-09-26 16:06:25,011 - INFO - Epoch [5/8], Loss: 0.3132618967683923\n",
      "Epoch 6/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1066.88it/s]\n",
      "2024-09-26 16:06:25,928 - INFO - Epoch [6/8], Loss: 0.3132618965853688\n",
      "Epoch 7/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1067.34it/s]\n",
      "2024-09-26 16:06:26,845 - INFO - Epoch [7/8], Loss: 0.3132618964938571\n",
      "Epoch 8/8: 100%|████████████████████████████| 977/977 [00:00<00:00, 1068.40it/s]\n",
      "2024-09-26 16:06:27,761 - INFO - Epoch [8/8], Loss: 0.31326189643284924\n",
      "Evaluating: 100%|███████████████████████████| 245/245 [00:00<00:00, 2515.99it/s]\n",
      "[I 2024-09-26 16:06:27,884] Trial 1 finished with value: 100.0 and parameters: {'hidden_size': 210, 'learning_rate': 0.0006918322528503578, 'batch_size': 32, 'num_epochs': 8}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1125.32it/s]\n",
      "2024-09-26 16:06:29,378 - INFO - Epoch [1/17], Loss: 0.3170211842410754\n",
      "Epoch 2/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1104.13it/s]\n",
      "2024-09-26 16:06:30,667 - INFO - Epoch [2/17], Loss: 0.3132648061774802\n",
      "Epoch 3/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1166.23it/s]\n",
      "2024-09-26 16:06:31,887 - INFO - Epoch [3/17], Loss: 0.31326246945309355\n",
      "Epoch 4/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1102.93it/s]\n",
      "2024-09-26 16:06:33,177 - INFO - Epoch [4/17], Loss: 0.3132620310170981\n",
      "Epoch 5/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1172.58it/s]\n",
      "2024-09-26 16:06:34,390 - INFO - Epoch [5/17], Loss: 0.3132619125628287\n",
      "Epoch 6/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1148.98it/s]\n",
      "2024-09-26 16:06:35,629 - INFO - Epoch [6/17], Loss: 0.31326188007599026\n",
      "Epoch 7/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1152.31it/s]\n",
      "2024-09-26 16:06:36,863 - INFO - Epoch [7/17], Loss: 0.3132618712045037\n",
      "Epoch 8/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1156.02it/s]\n",
      "2024-09-26 16:06:38,094 - INFO - Epoch [8/17], Loss: 0.31326186858290606\n",
      "Epoch 9/17: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1165.69it/s]\n",
      "2024-09-26 16:06:39,315 - INFO - Epoch [9/17], Loss: 0.3132618674503759\n",
      "Epoch 10/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1139.14it/s]\n",
      "2024-09-26 16:06:40,564 - INFO - Epoch [10/17], Loss: 0.3132618669680019\n",
      "Epoch 11/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1170.54it/s]\n",
      "2024-09-26 16:06:41,779 - INFO - Epoch [11/17], Loss: 0.3132618667373013\n",
      "Epoch 12/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1168.42it/s]\n",
      "2024-09-26 16:06:42,997 - INFO - Epoch [12/17], Loss: 0.3132618666324374\n",
      "Epoch 13/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1173.62it/s]\n",
      "2024-09-26 16:06:44,209 - INFO - Epoch [13/17], Loss: 0.3132618665904918\n",
      "Epoch 14/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1161.31it/s]\n",
      "2024-09-26 16:06:45,435 - INFO - Epoch [14/17], Loss: 0.31326186654854626\n",
      "Epoch 15/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1147.08it/s]\n",
      "2024-09-26 16:06:46,675 - INFO - Epoch [15/17], Loss: 0.31326186654854626\n",
      "Epoch 16/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1161.78it/s]\n",
      "2024-09-26 16:06:47,900 - INFO - Epoch [16/17], Loss: 0.3132618665275735\n",
      "Epoch 17/17: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1166.79it/s]\n",
      "2024-09-26 16:06:49,119 - INFO - Epoch [17/17], Loss: 0.3132618665275735\n",
      "Evaluating: 100%|███████████████████████████| 356/356 [00:00<00:00, 2739.67it/s]\n",
      "[I 2024-09-26 16:06:49,264] Trial 2 finished with value: 100.0 and parameters: {'hidden_size': 255, 'learning_rate': 0.00012354298845204548, 'batch_size': 22, 'num_epochs': 17}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 1002.60it/s]\n",
      "2024-09-26 16:06:50,131 - INFO - Epoch [1/20], Loss: 0.31776039896567176\n",
      "Epoch 2/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 1013.57it/s]\n",
      "2024-09-26 16:06:50,776 - INFO - Epoch [2/20], Loss: 0.3132642955959209\n",
      "Epoch 3/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 1000.47it/s]\n",
      "2024-09-26 16:06:51,429 - INFO - Epoch [3/20], Loss: 0.3132624580907675\n",
      "Epoch 4/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 1020.88it/s]\n",
      "2024-09-26 16:06:52,069 - INFO - Epoch [4/20], Loss: 0.3132620996401354\n",
      "Epoch 5/20: 100%|████████████████████████████| 652/652 [00:00<00:00, 979.50it/s]\n",
      "2024-09-26 16:06:52,736 - INFO - Epoch [5/20], Loss: 0.3132619686379023\n",
      "Epoch 6/20: 100%|████████████████████████████| 652/652 [00:00<00:00, 991.86it/s]\n",
      "2024-09-26 16:06:53,394 - INFO - Epoch [6/20], Loss: 0.31326191447263846\n",
      "Epoch 7/20: 100%|████████████████████████████| 652/652 [00:00<00:00, 971.67it/s]\n",
      "2024-09-26 16:06:54,067 - INFO - Epoch [7/20], Loss: 0.3132618898811516\n",
      "Epoch 8/20: 100%|████████████████████████████| 652/652 [00:00<00:00, 983.03it/s]\n",
      "2024-09-26 16:06:54,732 - INFO - Epoch [8/20], Loss: 0.3132618790938079\n",
      "Epoch 9/20: 100%|████████████████████████████| 652/652 [00:00<00:00, 973.01it/s]\n",
      "2024-09-26 16:06:55,403 - INFO - Epoch [9/20], Loss: 0.3132618738829724\n",
      "Epoch 10/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 959.35it/s]\n",
      "2024-09-26 16:06:56,084 - INFO - Epoch [10/20], Loss: 0.31326187091188196\n",
      "Epoch 11/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 993.10it/s]\n",
      "2024-09-26 16:06:56,743 - INFO - Epoch [11/20], Loss: 0.31326186931206407\n",
      "Epoch 12/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 891.80it/s]\n",
      "2024-09-26 16:06:57,475 - INFO - Epoch [12/20], Loss: 0.3132618683978824\n",
      "Epoch 13/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 902.46it/s]\n",
      "2024-09-26 16:06:58,199 - INFO - Epoch [13/20], Loss: 0.3132618678036643\n",
      "Epoch 14/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 863.54it/s]\n",
      "2024-09-26 16:06:58,956 - INFO - Epoch [14/20], Loss: 0.31326186734657346\n",
      "Epoch 15/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 867.39it/s]\n",
      "2024-09-26 16:06:59,709 - INFO - Epoch [15/20], Loss: 0.31326186707231896\n",
      "Epoch 16/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 983.12it/s]\n",
      "2024-09-26 16:07:00,374 - INFO - Epoch [16/20], Loss: 0.31326186688948265\n",
      "Epoch 17/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 959.23it/s]\n",
      "2024-09-26 16:07:01,055 - INFO - Epoch [17/20], Loss: 0.3132618667066463\n",
      "Epoch 18/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 891.73it/s]\n",
      "2024-09-26 16:07:01,788 - INFO - Epoch [18/20], Loss: 0.31326186661522815\n",
      "Epoch 19/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 972.98it/s]\n",
      "2024-09-26 16:07:02,460 - INFO - Epoch [19/20], Loss: 0.31326186656951904\n",
      "Epoch 20/20: 100%|███████████████████████████| 652/652 [00:00<00:00, 907.97it/s]\n",
      "2024-09-26 16:07:03,180 - INFO - Epoch [20/20], Loss: 0.31326186652380994\n",
      "Evaluating: 100%|███████████████████████████| 163/163 [00:00<00:00, 2042.01it/s]\n",
      "[I 2024-09-26 16:07:03,279] Trial 3 finished with value: 100.0 and parameters: {'hidden_size': 188, 'learning_rate': 0.00021627156207415187, 'batch_size': 48, 'num_epochs': 20}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1013.24it/s]\n",
      "2024-09-26 16:07:04,315 - INFO - Epoch [1/16], Loss: 0.34906979448014\n",
      "Epoch 2/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1039.95it/s]\n",
      "2024-09-26 16:07:05,000 - INFO - Epoch [2/16], Loss: 0.31427002154322115\n",
      "Epoch 3/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1019.46it/s]\n",
      "2024-09-26 16:07:05,699 - INFO - Epoch [3/16], Loss: 0.31358260285166917\n",
      "Epoch 4/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1028.32it/s]\n",
      "2024-09-26 16:07:06,392 - INFO - Epoch [4/16], Loss: 0.3134080014399838\n",
      "Epoch 5/16: 100%|████████████████████████████| 711/711 [00:00<00:00, 991.02it/s]\n",
      "2024-09-26 16:07:07,111 - INFO - Epoch [5/16], Loss: 0.3133395317569899\n",
      "Epoch 6/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1011.79it/s]\n",
      "2024-09-26 16:07:07,816 - INFO - Epoch [6/16], Loss: 0.313306678238465\n",
      "Epoch 7/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1045.97it/s]\n",
      "2024-09-26 16:07:08,497 - INFO - Epoch [7/16], Loss: 0.3132890412576088\n",
      "Epoch 8/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1054.74it/s]\n",
      "2024-09-26 16:07:09,173 - INFO - Epoch [8/16], Loss: 0.3132788502046663\n",
      "Epoch 9/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 1066.04it/s]\n",
      "2024-09-26 16:07:09,841 - INFO - Epoch [9/16], Loss: 0.313272671483237\n",
      "Epoch 10/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1032.76it/s]\n",
      "2024-09-26 16:07:10,531 - INFO - Epoch [10/16], Loss: 0.3132688142411652\n",
      "Epoch 11/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1018.33it/s]\n",
      "2024-09-26 16:07:11,231 - INFO - Epoch [11/16], Loss: 0.3132663690255832\n",
      "Epoch 12/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1025.68it/s]\n",
      "2024-09-26 16:07:11,926 - INFO - Epoch [12/16], Loss: 0.31326478149652814\n",
      "Epoch 13/16: 100%|███████████████████████████| 711/711 [00:00<00:00, 939.30it/s]\n",
      "2024-09-26 16:07:12,684 - INFO - Epoch [13/16], Loss: 0.31326375970860576\n",
      "Epoch 14/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1051.88it/s]\n",
      "2024-09-26 16:07:13,361 - INFO - Epoch [14/16], Loss: 0.31326310154254927\n",
      "Epoch 15/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1008.76it/s]\n",
      "2024-09-26 16:07:14,068 - INFO - Epoch [15/16], Loss: 0.3132626481364716\n",
      "Epoch 16/16: 100%|██████████████████████████| 711/711 [00:00<00:00, 1003.44it/s]\n",
      "2024-09-26 16:07:14,778 - INFO - Epoch [16/16], Loss: 0.31326236549644365\n",
      "Evaluating: 100%|███████████████████████████| 178/178 [00:00<00:00, 2141.36it/s]\n",
      "[I 2024-09-26 16:07:14,875] Trial 4 finished with value: 100.0 and parameters: {'hidden_size': 108, 'learning_rate': 3.135380113789256e-05, 'batch_size': 44, 'num_epochs': 16}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1003.52it/s]\n",
      "2024-09-26 16:07:15,875 - INFO - Epoch [1/10], Loss: 0.314926691397148\n",
      "Epoch 2/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1010.90it/s]\n",
      "2024-09-26 16:07:16,549 - INFO - Epoch [2/10], Loss: 0.31326257691663856\n",
      "Epoch 3/10: 100%|████████████████████████████| 680/680 [00:00<00:00, 977.23it/s]\n",
      "2024-09-26 16:07:17,246 - INFO - Epoch [3/10], Loss: 0.31326199910219976\n",
      "Epoch 4/10: 100%|████████████████████████████| 680/680 [00:00<00:00, 999.88it/s]\n",
      "2024-09-26 16:07:17,928 - INFO - Epoch [4/10], Loss: 0.313261901455767\n",
      "Epoch 5/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1019.35it/s]\n",
      "2024-09-26 16:07:18,596 - INFO - Epoch [5/10], Loss: 0.3132618773071205\n",
      "Epoch 6/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1021.64it/s]\n",
      "2024-09-26 16:07:19,263 - INFO - Epoch [6/10], Loss: 0.3132618712590021\n",
      "Epoch 7/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1026.80it/s]\n",
      "2024-09-26 16:07:19,927 - INFO - Epoch [7/10], Loss: 0.3132618690676549\n",
      "Epoch 8/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1001.62it/s]\n",
      "2024-09-26 16:07:20,607 - INFO - Epoch [8/10], Loss: 0.3132618679719813\n",
      "Epoch 9/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 1014.96it/s]\n",
      "2024-09-26 16:07:21,279 - INFO - Epoch [9/10], Loss: 0.31326186735840406\n",
      "Epoch 10/10: 100%|███████████████████████████| 680/680 [00:00<00:00, 990.38it/s]\n",
      "2024-09-26 16:07:21,967 - INFO - Epoch [10/10], Loss: 0.31326186705161546\n",
      "Evaluating: 100%|███████████████████████████| 170/170 [00:00<00:00, 2211.22it/s]\n",
      "[I 2024-09-26 16:07:22,058] Trial 5 finished with value: 100.0 and parameters: {'hidden_size': 167, 'learning_rate': 0.0006316182784046022, 'batch_size': 46, 'num_epochs': 10}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/5: 100%|██████████████████████████| 1042/1042 [00:00<00:00, 1078.65it/s]\n",
      "2024-09-26 16:07:23,381 - INFO - Epoch [1/5], Loss: 0.314831278717678\n",
      "Epoch 2/5: 100%|██████████████████████████| 1042/1042 [00:00<00:00, 1165.53it/s]\n",
      "2024-09-26 16:07:24,277 - INFO - Epoch [2/5], Loss: 0.3132628046562484\n",
      "Epoch 3/5: 100%|██████████████████████████| 1042/1042 [00:00<00:00, 1124.89it/s]\n",
      "2024-09-26 16:07:25,204 - INFO - Epoch [3/5], Loss: 0.3132620911451768\n",
      "Epoch 4/5: 100%|██████████████████████████| 1042/1042 [00:00<00:00, 1133.71it/s]\n",
      "2024-09-26 16:07:26,125 - INFO - Epoch [4/5], Loss: 0.31326195188653216\n",
      "Epoch 5/5: 100%|██████████████████████████| 1042/1042 [00:00<00:00, 1190.62it/s]\n",
      "2024-09-26 16:07:27,002 - INFO - Epoch [5/5], Loss: 0.31326191310347157\n",
      "Evaluating: 100%|███████████████████████████| 261/261 [00:00<00:00, 2398.06it/s]\n",
      "[I 2024-09-26 16:07:27,128] Trial 6 finished with value: 100.0 and parameters: {'hidden_size': 76, 'learning_rate': 0.0006974274891811403, 'batch_size': 30, 'num_epochs': 5}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1153.53it/s]\n",
      "2024-09-26 16:07:28,570 - INFO - Epoch [1/14], Loss: 0.31433218998610346\n",
      "Epoch 2/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1118.74it/s]\n",
      "2024-09-26 16:07:29,842 - INFO - Epoch [2/14], Loss: 0.313262654873454\n",
      "Epoch 3/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1108.83it/s]\n",
      "2024-09-26 16:07:31,125 - INFO - Epoch [3/14], Loss: 0.3132619833879115\n",
      "Epoch 4/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1125.22it/s]\n",
      "2024-09-26 16:07:32,389 - INFO - Epoch [4/14], Loss: 0.31326188697603535\n",
      "Epoch 5/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1141.67it/s]\n",
      "2024-09-26 16:07:33,635 - INFO - Epoch [5/14], Loss: 0.31326187086893925\n",
      "Epoch 6/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1092.93it/s]\n",
      "2024-09-26 16:07:34,937 - INFO - Epoch [6/14], Loss: 0.31326186782788595\n",
      "Epoch 7/14: 100%|██████████████████████████| 1421/1421 [00:01<00:00, 930.21it/s]\n",
      "2024-09-26 16:07:36,466 - INFO - Epoch [7/14], Loss: 0.31326186692605634\n",
      "Epoch 8/14: 100%|██████████████████████████| 1421/1421 [00:01<00:00, 986.08it/s]\n",
      "2024-09-26 16:07:37,909 - INFO - Epoch [8/14], Loss: 0.31326186667438294\n",
      "Epoch 9/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 1032.63it/s]\n",
      "2024-09-26 16:07:39,287 - INFO - Epoch [9/14], Loss: 0.3132618666114646\n",
      "Epoch 10/14: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1023.92it/s]\n",
      "2024-09-26 16:07:40,677 - INFO - Epoch [10/14], Loss: 0.31326186654854626\n",
      "Epoch 11/14: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1006.09it/s]\n",
      "2024-09-26 16:07:42,091 - INFO - Epoch [11/14], Loss: 0.3132618665275735\n",
      "Epoch 12/14: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1025.95it/s]\n",
      "2024-09-26 16:07:43,477 - INFO - Epoch [12/14], Loss: 0.3132618665275735\n",
      "Epoch 13/14: 100%|█████████████████████████| 1421/1421 [00:01<00:00, 957.91it/s]\n",
      "2024-09-26 16:07:44,963 - INFO - Epoch [13/14], Loss: 0.3132618665275735\n",
      "Epoch 14/14: 100%|████████████████████████| 1421/1421 [00:01<00:00, 1040.71it/s]\n",
      "2024-09-26 16:07:46,330 - INFO - Epoch [14/14], Loss: 0.3132618665275735\n",
      "Evaluating: 100%|███████████████████████████| 356/356 [00:00<00:00, 2592.55it/s]\n",
      "[I 2024-09-26 16:07:46,484] Trial 7 finished with value: 100.0 and parameters: {'hidden_size': 193, 'learning_rate': 0.0003493962483452267, 'batch_size': 22, 'num_epochs': 14}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 834.22it/s]\n",
      "2024-09-26 16:07:47,504 - INFO - Epoch [1/20], Loss: 0.3705763694506056\n",
      "Epoch 2/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 842.26it/s]\n",
      "2024-09-26 16:07:48,096 - INFO - Epoch [2/20], Loss: 0.31537518354968525\n",
      "Epoch 3/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 796.02it/s]\n",
      "2024-09-26 16:07:48,722 - INFO - Epoch [3/20], Loss: 0.31395169390998856\n",
      "Epoch 4/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 849.33it/s]\n",
      "2024-09-26 16:07:49,310 - INFO - Epoch [4/20], Loss: 0.31359254774193407\n",
      "Epoch 5/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 796.78it/s]\n",
      "2024-09-26 16:07:49,936 - INFO - Epoch [5/20], Loss: 0.3134485011849125\n",
      "Epoch 6/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 791.36it/s]\n",
      "2024-09-26 16:07:50,565 - INFO - Epoch [6/20], Loss: 0.31337746162289826\n",
      "Epoch 7/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 812.25it/s]\n",
      "2024-09-26 16:07:51,179 - INFO - Epoch [7/20], Loss: 0.3133375254915034\n",
      "Epoch 8/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 814.62it/s]\n",
      "2024-09-26 16:07:51,791 - INFO - Epoch [8/20], Loss: 0.3133132106941231\n",
      "Epoch 9/20: 100%|████████████████████████████| 497/497 [00:00<00:00, 845.00it/s]\n",
      "2024-09-26 16:07:52,381 - INFO - Epoch [9/20], Loss: 0.31329778688294546\n",
      "Epoch 10/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 789.82it/s]\n",
      "2024-09-26 16:07:53,013 - INFO - Epoch [10/20], Loss: 0.31328742562885015\n",
      "Epoch 11/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 793.96it/s]\n",
      "2024-09-26 16:07:53,641 - INFO - Epoch [11/20], Loss: 0.31328030113483096\n",
      "Epoch 12/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 744.32it/s]\n",
      "2024-09-26 16:07:54,311 - INFO - Epoch [12/20], Loss: 0.3132751239257559\n",
      "Epoch 13/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 847.43it/s]\n",
      "2024-09-26 16:07:54,899 - INFO - Epoch [13/20], Loss: 0.31327133903081267\n",
      "Epoch 14/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 808.38it/s]\n",
      "2024-09-26 16:07:55,516 - INFO - Epoch [14/20], Loss: 0.3132685812666143\n",
      "Epoch 15/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 789.86it/s]\n",
      "2024-09-26 16:07:56,147 - INFO - Epoch [15/20], Loss: 0.3132666107754352\n",
      "Epoch 16/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 776.49it/s]\n",
      "2024-09-26 16:07:56,789 - INFO - Epoch [16/20], Loss: 0.313265228415399\n",
      "Epoch 17/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 865.43it/s]\n",
      "2024-09-26 16:07:57,364 - INFO - Epoch [17/20], Loss: 0.3132642577111841\n",
      "Epoch 18/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 870.07it/s]\n",
      "2024-09-26 16:07:57,937 - INFO - Epoch [18/20], Loss: 0.31326356530189514\n",
      "Epoch 19/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 891.27it/s]\n",
      "2024-09-26 16:07:58,496 - INFO - Epoch [19/20], Loss: 0.3132630899638477\n",
      "Epoch 20/20: 100%|███████████████████████████| 497/497 [00:00<00:00, 841.94it/s]\n",
      "2024-09-26 16:07:59,087 - INFO - Epoch [20/20], Loss: 0.31326274306961227\n",
      "Evaluating: 100%|███████████████████████████| 125/125 [00:00<00:00, 1819.04it/s]\n",
      "[I 2024-09-26 16:07:59,173] Trial 8 finished with value: 100.0 and parameters: {'hidden_size': 221, 'learning_rate': 2.112991869234891e-05, 'batch_size': 63, 'num_epochs': 20}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 798.75it/s]\n",
      "2024-09-26 16:08:00,117 - INFO - Epoch [1/19], Loss: 0.3406967372601661\n",
      "Epoch 2/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 855.09it/s]\n",
      "2024-09-26 16:08:00,700 - INFO - Epoch [2/19], Loss: 0.31371182005410225\n",
      "Epoch 3/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 894.12it/s]\n",
      "2024-09-26 16:08:01,258 - INFO - Epoch [3/19], Loss: 0.31339500019967675\n",
      "Epoch 4/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 784.13it/s]\n",
      "2024-09-26 16:08:01,894 - INFO - Epoch [4/19], Loss: 0.31331990152537464\n",
      "Epoch 5/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 781.04it/s]\n",
      "2024-09-26 16:08:02,531 - INFO - Epoch [5/19], Loss: 0.31329210543296704\n",
      "Epoch 6/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 842.37it/s]\n",
      "2024-09-26 16:08:03,123 - INFO - Epoch [6/19], Loss: 0.3132792747836238\n",
      "Epoch 7/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 857.91it/s]\n",
      "2024-09-26 16:08:03,705 - INFO - Epoch [7/19], Loss: 0.3132725694409798\n",
      "Epoch 8/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 825.54it/s]\n",
      "2024-09-26 16:08:04,310 - INFO - Epoch [8/19], Loss: 0.31326876223926814\n",
      "Epoch 9/19: 100%|████████████████████████████| 497/497 [00:00<00:00, 822.16it/s]\n",
      "2024-09-26 16:08:04,916 - INFO - Epoch [9/19], Loss: 0.31326646008481923\n",
      "Epoch 10/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 863.70it/s]\n",
      "2024-09-26 16:08:05,493 - INFO - Epoch [10/19], Loss: 0.31326498753827825\n",
      "Epoch 11/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 730.88it/s]\n",
      "2024-09-26 16:08:06,175 - INFO - Epoch [11/19], Loss: 0.31326401155719336\n",
      "Epoch 12/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 840.82it/s]\n",
      "2024-09-26 16:08:06,768 - INFO - Epoch [12/19], Loss: 0.3132633529678437\n",
      "Epoch 13/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 729.23it/s]\n",
      "2024-09-26 16:08:07,452 - INFO - Epoch [13/19], Loss: 0.31326290911112276\n",
      "Epoch 14/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 760.96it/s]\n",
      "2024-09-26 16:08:08,107 - INFO - Epoch [14/19], Loss: 0.3132625975359374\n",
      "Epoch 15/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 775.30it/s]\n",
      "2024-09-26 16:08:08,751 - INFO - Epoch [15/19], Loss: 0.3132623813641623\n",
      "Epoch 16/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 777.26it/s]\n",
      "2024-09-26 16:08:09,393 - INFO - Epoch [16/19], Loss: 0.31326222911447105\n",
      "Epoch 17/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 787.24it/s]\n",
      "2024-09-26 16:08:10,026 - INFO - Epoch [17/19], Loss: 0.3132621196194194\n",
      "Epoch 18/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 798.35it/s]\n",
      "2024-09-26 16:08:10,650 - INFO - Epoch [18/19], Loss: 0.3132620366886108\n",
      "Epoch 19/19: 100%|███████████████████████████| 497/497 [00:00<00:00, 853.73it/s]\n",
      "2024-09-26 16:08:11,234 - INFO - Epoch [19/19], Loss: 0.313261976244464\n",
      "Evaluating: 100%|███████████████████████████| 125/125 [00:00<00:00, 1539.29it/s]\n",
      "[I 2024-09-26 16:08:11,334] Trial 9 finished with value: 100.0 and parameters: {'hidden_size': 191, 'learning_rate': 4.6662423081280996e-05, 'batch_size': 63, 'num_epochs': 19}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/5: 100%|█████████████████████████████| 559/559 [00:00<00:00, 840.95it/s]\n",
      "2024-09-26 16:08:12,292 - INFO - Epoch [1/5], Loss: 0.3139762403393474\n",
      "Epoch 2/5: 100%|█████████████████████████████| 559/559 [00:00<00:00, 761.57it/s]\n",
      "2024-09-26 16:08:13,028 - INFO - Epoch [2/5], Loss: 0.313261806858247\n",
      "Epoch 3/5: 100%|█████████████████████████████| 559/559 [00:00<00:00, 871.67it/s]\n",
      "2024-09-26 16:08:13,671 - INFO - Epoch [3/5], Loss: 0.313261806858247\n",
      "Epoch 4/5: 100%|█████████████████████████████| 559/559 [00:00<00:00, 780.30it/s]\n",
      "2024-09-26 16:08:14,389 - INFO - Epoch [4/5], Loss: 0.313261806858247\n",
      "Epoch 5/5: 100%|█████████████████████████████| 559/559 [00:00<00:00, 827.68it/s]\n",
      "2024-09-26 16:08:15,067 - INFO - Epoch [5/5], Loss: 0.313261806858247\n",
      "Evaluating: 100%|███████████████████████████| 140/140 [00:00<00:00, 1464.89it/s]\n",
      "[I 2024-09-26 16:08:15,179] Trial 10 finished with value: 100.0 and parameters: {'hidden_size': 136, 'learning_rate': 0.007476545305916122, 'batch_size': 56, 'num_epochs': 5}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 920.96it/s]\n",
      "2024-09-26 16:08:16,567 - INFO - Epoch [1/9], Loss: 0.31380736458560693\n",
      "Epoch 2/9: 100%|█████████████████████████████| 920/920 [00:01<00:00, 897.03it/s]\n",
      "2024-09-26 16:08:17,594 - INFO - Epoch [2/9], Loss: 0.3132619022351244\n",
      "Epoch 3/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 998.07it/s]\n",
      "2024-09-26 16:08:18,518 - INFO - Epoch [3/9], Loss: 0.3132619003886762\n",
      "Epoch 4/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 982.16it/s]\n",
      "2024-09-26 16:08:19,456 - INFO - Epoch [4/9], Loss: 0.31326189886616623\n",
      "Epoch 5/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 995.90it/s]\n",
      "2024-09-26 16:08:20,381 - INFO - Epoch [5/9], Loss: 0.31326189808871435\n",
      "Epoch 6/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 955.58it/s]\n",
      "2024-09-26 16:08:21,345 - INFO - Epoch [6/9], Loss: 0.313261897214081\n",
      "Epoch 7/9: 100%|█████████████████████████████| 920/920 [00:01<00:00, 904.59it/s]\n",
      "2024-09-26 16:08:22,364 - INFO - Epoch [7/9], Loss: 0.31326189682535505\n",
      "Epoch 8/9: 100%|█████████████████████████████| 920/920 [00:01<00:00, 914.11it/s]\n",
      "2024-09-26 16:08:23,372 - INFO - Epoch [8/9], Loss: 0.3132618965662044\n",
      "Epoch 9/9: 100%|█████████████████████████████| 920/920 [00:00<00:00, 926.08it/s]\n",
      "2024-09-26 16:08:24,367 - INFO - Epoch [9/9], Loss: 0.3132618964366291\n",
      "Evaluating: 100%|███████████████████████████| 230/230 [00:00<00:00, 2220.76it/s]\n",
      "[I 2024-09-26 16:08:24,492] Trial 11 finished with value: 100.0 and parameters: {'hidden_size': 236, 'learning_rate': 0.003165988134687426, 'batch_size': 34, 'num_epochs': 9}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 908.53it/s]\n",
      "2024-09-26 16:08:25,878 - INFO - Epoch [1/8], Loss: 0.3137950523058756\n",
      "Epoch 2/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 945.42it/s]\n",
      "2024-09-26 16:08:26,800 - INFO - Epoch [2/8], Loss: 0.3132618996984528\n",
      "Epoch 3/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 968.04it/s]\n",
      "2024-09-26 16:08:27,703 - INFO - Epoch [3/8], Loss: 0.31326189644043134\n",
      "Epoch 4/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 966.41it/s]\n",
      "2024-09-26 16:08:28,604 - INFO - Epoch [4/8], Loss: 0.31326189626895656\n",
      "Epoch 5/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 971.76it/s]\n",
      "2024-09-26 16:08:29,501 - INFO - Epoch [5/8], Loss: 0.3132618962346616\n",
      "Epoch 6/8: 100%|█████████████████████████████| 869/869 [00:01<00:00, 848.27it/s]\n",
      "2024-09-26 16:08:30,527 - INFO - Epoch [6/8], Loss: 0.3132618962003666\n",
      "Epoch 7/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 961.59it/s]\n",
      "2024-09-26 16:08:31,436 - INFO - Epoch [7/8], Loss: 0.3132618962003666\n",
      "Epoch 8/8: 100%|█████████████████████████████| 869/869 [00:00<00:00, 980.44it/s]\n",
      "2024-09-26 16:08:32,324 - INFO - Epoch [8/8], Loss: 0.3132618962003666\n",
      "Evaluating: 100%|███████████████████████████| 218/218 [00:00<00:00, 2308.61it/s]\n",
      "[I 2024-09-26 16:08:32,434] Trial 12 finished with value: 100.0 and parameters: {'hidden_size': 217, 'learning_rate': 0.001766812719249404, 'batch_size': 36, 'num_epochs': 8}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 995.31it/s]\n",
      "2024-09-26 16:08:33,960 - INFO - Epoch [1/11], Loss: 0.3137192387824199\n",
      "Epoch 2/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 972.43it/s]\n",
      "2024-09-26 16:08:35,111 - INFO - Epoch [2/11], Loss: 0.313261897412388\n",
      "Epoch 3/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 982.62it/s]\n",
      "2024-09-26 16:08:36,250 - INFO - Epoch [3/11], Loss: 0.31326189631848006\n",
      "Epoch 4/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 980.86it/s]\n",
      "2024-09-26 16:08:37,390 - INFO - Epoch [4/11], Loss: 0.3132618962651187\n",
      "Epoch 5/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 996.24it/s]\n",
      "2024-09-26 16:08:38,513 - INFO - Epoch [5/11], Loss: 0.31326189623843803\n",
      "Epoch 6/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 997.73it/s]\n",
      "2024-09-26 16:08:39,634 - INFO - Epoch [6/11], Loss: 0.31326189623843803\n",
      "Epoch 7/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 957.64it/s]\n",
      "2024-09-26 16:08:40,802 - INFO - Epoch [7/11], Loss: 0.31326189623843803\n",
      "Epoch 8/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 955.58it/s]\n",
      "2024-09-26 16:08:41,973 - INFO - Epoch [8/11], Loss: 0.31326189623843803\n",
      "Epoch 9/11: 100%|██████████████████████████| 1117/1117 [00:01<00:00, 990.14it/s]\n",
      "2024-09-26 16:08:43,103 - INFO - Epoch [9/11], Loss: 0.31326189623843803\n",
      "Epoch 10/11: 100%|█████████████████████████| 1117/1117 [00:01<00:00, 978.36it/s]\n",
      "2024-09-26 16:08:44,247 - INFO - Epoch [10/11], Loss: 0.31326189623843803\n",
      "Epoch 11/11: 100%|████████████████████████| 1117/1117 [00:01<00:00, 1018.85it/s]\n",
      "2024-09-26 16:08:45,345 - INFO - Epoch [11/11], Loss: 0.31326189623843803\n",
      "Evaluating: 100%|███████████████████████████| 280/280 [00:00<00:00, 2198.87it/s]\n",
      "[I 2024-09-26 16:08:45,498] Trial 13 finished with value: 100.0 and parameters: {'hidden_size': 245, 'learning_rate': 0.0019286316376074173, 'batch_size': 28, 'num_epochs': 11}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1195.55it/s]\n",
      "2024-09-26 16:08:47,412 - INFO - Epoch [1/7], Loss: 0.31348318442656536\n",
      "Epoch 2/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1112.53it/s]\n",
      "2024-09-26 16:08:49,170 - INFO - Epoch [2/7], Loss: 0.3132618070258821\n",
      "Epoch 3/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1147.95it/s]\n",
      "2024-09-26 16:08:50,874 - INFO - Epoch [3/7], Loss: 0.31326180693437033\n",
      "Epoch 4/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1132.00it/s]\n",
      "2024-09-26 16:08:52,601 - INFO - Epoch [4/7], Loss: 0.31326180693437033\n",
      "Epoch 5/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1125.89it/s]\n",
      "2024-09-26 16:08:54,338 - INFO - Epoch [5/7], Loss: 0.31326180693437033\n",
      "Epoch 6/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1020.14it/s]\n",
      "2024-09-26 16:08:56,256 - INFO - Epoch [6/7], Loss: 0.31326180693437033\n",
      "Epoch 7/7: 100%|██████████████████████████| 1954/1954 [00:01<00:00, 1130.58it/s]\n",
      "2024-09-26 16:08:57,986 - INFO - Epoch [7/7], Loss: 0.31326180693437033\n",
      "Evaluating: 100%|███████████████████████████| 489/489 [00:00<00:00, 3125.03it/s]\n",
      "[I 2024-09-26 16:08:58,154] Trial 14 finished with value: 100.0 and parameters: {'hidden_size': 153, 'learning_rate': 0.004908117466317843, 'batch_size': 16, 'num_epochs': 7}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 843.35it/s]\n",
      "2024-09-26 16:08:59,063 - INFO - Epoch [1/12], Loss: 0.3143002259093039\n",
      "Epoch 2/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 963.38it/s]\n",
      "2024-09-26 16:08:59,665 - INFO - Epoch [2/12], Loss: 0.3132623203986667\n",
      "Epoch 3/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 802.39it/s]\n",
      "2024-09-26 16:09:00,388 - INFO - Epoch [3/12], Loss: 0.3132620134193045\n",
      "Epoch 4/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 924.18it/s]\n",
      "2024-09-26 16:09:01,016 - INFO - Epoch [4/12], Loss: 0.3132619005925503\n",
      "Epoch 5/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 829.27it/s]\n",
      "2024-09-26 16:09:01,717 - INFO - Epoch [5/12], Loss: 0.31326185920901456\n",
      "Epoch 6/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 873.30it/s]\n",
      "2024-09-26 16:09:02,382 - INFO - Epoch [6/12], Loss: 0.31326184742191293\n",
      "Epoch 7/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 865.01it/s]\n",
      "2024-09-26 16:09:03,053 - INFO - Epoch [7/12], Loss: 0.3132618420688188\n",
      "Epoch 8/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 886.43it/s]\n",
      "2024-09-26 16:09:03,708 - INFO - Epoch [8/12], Loss: 0.31326183995846435\n",
      "Epoch 9/12: 100%|████████████████████████████| 579/579 [00:00<00:00, 968.49it/s]\n",
      "2024-09-26 16:09:04,307 - INFO - Epoch [9/12], Loss: 0.31326183851724665\n",
      "Epoch 10/12: 100%|███████████████████████████| 579/579 [00:00<00:00, 902.11it/s]\n",
      "2024-09-26 16:09:04,951 - INFO - Epoch [10/12], Loss: 0.3132618377451658\n",
      "Epoch 11/12: 100%|███████████████████████████| 579/579 [00:00<00:00, 856.58it/s]\n",
      "2024-09-26 16:09:05,628 - INFO - Epoch [11/12], Loss: 0.3132618374363334\n",
      "Epoch 12/12: 100%|███████████████████████████| 579/579 [00:00<00:00, 905.99it/s]\n",
      "2024-09-26 16:09:06,269 - INFO - Epoch [12/12], Loss: 0.31326183717897316\n",
      "Evaluating: 100%|███████████████████████████| 145/145 [00:00<00:00, 1671.16it/s]\n",
      "[I 2024-09-26 16:09:06,383] Trial 15 finished with value: 100.0 and parameters: {'hidden_size': 214, 'learning_rate': 0.0011117481387346027, 'batch_size': 54, 'num_epochs': 12}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/6: 100%|█████████████████████████████| 802/802 [00:00<00:00, 934.41it/s]\n",
      "2024-09-26 16:09:07,524 - INFO - Epoch [1/6], Loss: 0.32106396399828563\n",
      "Epoch 2/6: 100%|█████████████████████████████| 802/802 [00:00<00:00, 976.40it/s]\n",
      "2024-09-26 16:09:08,347 - INFO - Epoch [2/6], Loss: 0.31329912422898404\n",
      "Epoch 3/6: 100%|█████████████████████████████| 802/802 [00:00<00:00, 973.48it/s]\n",
      "2024-09-26 16:09:09,173 - INFO - Epoch [3/6], Loss: 0.3132727276208692\n",
      "Epoch 4/6: 100%|████████████████████████████| 802/802 [00:00<00:00, 1064.81it/s]\n",
      "2024-09-26 16:09:09,927 - INFO - Epoch [4/6], Loss: 0.31326638998236145\n",
      "Epoch 5/6: 100%|████████████████████████████| 802/802 [00:00<00:00, 1019.24it/s]\n",
      "2024-09-26 16:09:10,716 - INFO - Epoch [5/6], Loss: 0.31326405194929413\n",
      "Epoch 6/6: 100%|████████████████████████████| 802/802 [00:00<00:00, 1006.23it/s]\n",
      "2024-09-26 16:09:11,514 - INFO - Epoch [6/6], Loss: 0.31326300481757025\n",
      "Evaluating: 100%|███████████████████████████| 201/201 [00:00<00:00, 2390.97it/s]\n",
      "[I 2024-09-26 16:09:11,611] Trial 16 finished with value: 100.0 and parameters: {'hidden_size': 175, 'learning_rate': 9.818400538250485e-05, 'batch_size': 39, 'num_epochs': 6}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 845.75it/s]\n",
      "2024-09-26 16:09:12,522 - INFO - Epoch [1/8], Loss: 0.3139449099596712\n",
      "Epoch 2/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 798.42it/s]\n",
      "2024-09-26 16:09:13,249 - INFO - Epoch [2/8], Loss: 0.3132618368186687\n",
      "Epoch 3/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 820.66it/s]\n",
      "2024-09-26 16:09:13,957 - INFO - Epoch [3/8], Loss: 0.3132618368186687\n",
      "Epoch 4/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 885.77it/s]\n",
      "2024-09-26 16:09:14,612 - INFO - Epoch [4/8], Loss: 0.3132618368186687\n",
      "Epoch 5/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 905.40it/s]\n",
      "2024-09-26 16:09:15,254 - INFO - Epoch [5/8], Loss: 0.3132618368186687\n",
      "Epoch 6/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 937.90it/s]\n",
      "2024-09-26 16:09:15,872 - INFO - Epoch [6/8], Loss: 0.3132618368186687\n",
      "Epoch 7/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 963.52it/s]\n",
      "2024-09-26 16:09:16,475 - INFO - Epoch [7/8], Loss: 0.3132618368186687\n",
      "Epoch 8/8: 100%|█████████████████████████████| 579/579 [00:00<00:00, 958.46it/s]\n",
      "2024-09-26 16:09:17,080 - INFO - Epoch [8/8], Loss: 0.3132618368186687\n",
      "Evaluating: 100%|███████████████████████████| 145/145 [00:00<00:00, 1828.67it/s]\n",
      "[I 2024-09-26 16:09:17,171] Trial 17 finished with value: 100.0 and parameters: {'hidden_size': 211, 'learning_rate': 0.009463584448187071, 'batch_size': 54, 'num_epochs': 8}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1011.89it/s]\n",
      "2024-09-26 16:09:18,111 - INFO - Epoch [1/14], Loss: 0.31388666741799987\n",
      "Epoch 2/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1055.29it/s]\n",
      "2024-09-26 16:09:18,819 - INFO - Epoch [2/14], Loss: 0.31326187553021734\n",
      "Epoch 3/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1063.36it/s]\n",
      "2024-09-26 16:09:19,521 - INFO - Epoch [3/14], Loss: 0.3132618695697528\n",
      "Epoch 4/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1042.48it/s]\n",
      "2024-09-26 16:09:20,237 - INFO - Epoch [4/14], Loss: 0.31326186752959384\n",
      "Epoch 5/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1051.03it/s]\n",
      "2024-09-26 16:09:20,947 - INFO - Epoch [5/14], Loss: 0.313261866889544\n",
      "Epoch 6/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1055.04it/s]\n",
      "2024-09-26 16:09:21,655 - INFO - Epoch [6/14], Loss: 0.31326186664952527\n",
      "Epoch 7/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1044.03it/s]\n",
      "2024-09-26 16:09:22,369 - INFO - Epoch [7/14], Loss: 0.31326186652951593\n",
      "Epoch 8/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1069.94it/s]\n",
      "2024-09-26 16:09:23,067 - INFO - Epoch [8/14], Loss: 0.3132618664895128\n",
      "Epoch 9/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 1062.29it/s]\n",
      "2024-09-26 16:09:23,770 - INFO - Epoch [9/14], Loss: 0.3132618664495097\n",
      "Epoch 10/14: 100%|██████████████████████████| 745/745 [00:00<00:00, 1033.10it/s]\n",
      "2024-09-26 16:09:24,492 - INFO - Epoch [10/14], Loss: 0.3132618664495097\n",
      "Epoch 11/14: 100%|██████████████████████████| 745/745 [00:00<00:00, 1048.05it/s]\n",
      "2024-09-26 16:09:25,205 - INFO - Epoch [11/14], Loss: 0.3132618664095066\n",
      "Epoch 12/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 782.32it/s]\n",
      "2024-09-26 16:09:26,159 - INFO - Epoch [12/14], Loss: 0.3132618664095066\n",
      "Epoch 13/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 786.70it/s]\n",
      "2024-09-26 16:09:27,110 - INFO - Epoch [13/14], Loss: 0.3132618664095066\n",
      "Epoch 14/14: 100%|███████████████████████████| 745/745 [00:00<00:00, 875.40it/s]\n",
      "2024-09-26 16:09:27,964 - INFO - Epoch [14/14], Loss: 0.3132618664095066\n",
      "Evaluating: 100%|███████████████████████████| 187/187 [00:00<00:00, 1730.24it/s]\n",
      "[I 2024-09-26 16:09:28,106] Trial 18 finished with value: 100.0 and parameters: {'hidden_size': 143, 'learning_rate': 0.0027986421709488883, 'batch_size': 42, 'num_epochs': 14}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 829.89it/s]\n",
      "2024-09-26 16:09:29,249 - INFO - Epoch [1/10], Loss: 0.3145587017356789\n",
      "Epoch 2/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 892.86it/s]\n",
      "2024-09-26 16:09:29,965 - INFO - Epoch [2/10], Loss: 0.31326300344870756\n",
      "Epoch 3/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 860.21it/s]\n",
      "2024-09-26 16:09:30,708 - INFO - Epoch [3/10], Loss: 0.3132621425446298\n",
      "Epoch 4/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 870.87it/s]\n",
      "2024-09-26 16:09:31,442 - INFO - Epoch [4/10], Loss: 0.3132619430839455\n",
      "Epoch 5/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 887.80it/s]\n",
      "2024-09-26 16:09:32,163 - INFO - Epoch [5/10], Loss: 0.31326189109337366\n",
      "Epoch 6/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 892.58it/s]\n",
      "2024-09-26 16:09:32,879 - INFO - Epoch [6/10], Loss: 0.3132618762856367\n",
      "Epoch 7/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 853.43it/s]\n",
      "2024-09-26 16:09:33,628 - INFO - Epoch [7/10], Loss: 0.3132618720815473\n",
      "Epoch 8/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 749.02it/s]\n",
      "2024-09-26 16:09:34,481 - INFO - Epoch [8/10], Loss: 0.31326186969923003\n",
      "Epoch 9/10: 100%|████████████████████████████| 638/638 [00:00<00:00, 806.22it/s]\n",
      "2024-09-26 16:09:35,274 - INFO - Epoch [9/10], Loss: 0.313261868344579\n",
      "Epoch 10/10: 100%|███████████████████████████| 638/638 [00:00<00:00, 747.38it/s]\n",
      "2024-09-26 16:09:36,130 - INFO - Epoch [10/10], Loss: 0.31326186778403375\n",
      "Evaluating: 100%|███████████████████████████| 160/160 [00:00<00:00, 1763.00it/s]\n",
      "[I 2024-09-26 16:09:36,241] Trial 19 finished with value: 100.0 and parameters: {'hidden_size': 233, 'learning_rate': 0.00075184605988686, 'batch_size': 49, 'num_epochs': 10}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 916.32it/s]\n",
      "2024-09-26 16:09:37,784 - INFO - Epoch [1/7], Loss: 0.31502042178801065\n",
      "Epoch 2/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 947.05it/s]\n",
      "2024-09-26 16:09:38,886 - INFO - Epoch [2/7], Loss: 0.31326282290373564\n",
      "Epoch 3/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 935.49it/s]\n",
      "2024-09-26 16:09:40,001 - INFO - Epoch [3/7], Loss: 0.3132620966937858\n",
      "Epoch 4/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 953.76it/s]\n",
      "2024-09-26 16:09:41,095 - INFO - Epoch [4/7], Loss: 0.31326195780695515\n",
      "Epoch 5/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 952.96it/s]\n",
      "2024-09-26 16:09:42,191 - INFO - Epoch [5/7], Loss: 0.3132619172220267\n",
      "Epoch 6/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 945.27it/s]\n",
      "2024-09-26 16:09:43,295 - INFO - Epoch [6/7], Loss: 0.3132619041513344\n",
      "Epoch 7/7: 100%|███████████████████████████| 1042/1042 [00:01<00:00, 853.14it/s]\n",
      "2024-09-26 16:09:44,518 - INFO - Epoch [7/7], Loss: 0.3132618997753696\n",
      "Evaluating: 100%|███████████████████████████| 261/261 [00:00<00:00, 2338.85it/s]\n",
      "[I 2024-09-26 16:09:44,651] Trial 20 finished with value: 100.0 and parameters: {'hidden_size': 199, 'learning_rate': 0.0003784551009106143, 'batch_size': 30, 'num_epochs': 7}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/17: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 968.23it/s]\n",
      "2024-09-26 16:09:46,575 - INFO - Epoch [1/17], Loss: 0.31797749727328445\n",
      "Epoch 2/17: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 990.76it/s]\n",
      "2024-09-26 16:09:47,949 - INFO - Epoch [2/17], Loss: 0.31327020615405066\n",
      "Epoch 3/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1001.76it/s]\n",
      "2024-09-26 16:09:49,308 - INFO - Epoch [3/17], Loss: 0.3132638516585734\n",
      "Epoch 4/17: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 978.15it/s]\n",
      "2024-09-26 16:09:50,699 - INFO - Epoch [4/17], Loss: 0.31326252686968614\n",
      "Epoch 5/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1047.82it/s]\n",
      "2024-09-26 16:09:51,998 - INFO - Epoch [5/17], Loss: 0.3132621082775377\n",
      "Epoch 6/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1044.03it/s]\n",
      "2024-09-26 16:09:53,302 - INFO - Epoch [6/17], Loss: 0.313261950274791\n",
      "Epoch 7/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1026.61it/s]\n",
      "2024-09-26 16:09:54,628 - INFO - Epoch [7/17], Loss: 0.31326189450782566\n",
      "Epoch 8/17: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 964.21it/s]\n",
      "2024-09-26 16:09:56,039 - INFO - Epoch [8/17], Loss: 0.31326187637204894\n",
      "Epoch 9/17: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 961.65it/s]\n",
      "2024-09-26 16:09:57,455 - INFO - Epoch [9/17], Loss: 0.3132618706703537\n",
      "Epoch 10/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 976.60it/s]\n",
      "2024-09-26 16:09:58,848 - INFO - Epoch [10/17], Loss: 0.313261868367746\n",
      "Epoch 11/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 972.41it/s]\n",
      "2024-09-26 16:10:00,247 - INFO - Epoch [11/17], Loss: 0.31326186740284373\n",
      "Epoch 12/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 994.38it/s]\n",
      "2024-09-26 16:10:01,616 - INFO - Epoch [12/17], Loss: 0.3132618669861814\n",
      "Epoch 13/17: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 941.29it/s]\n",
      "2024-09-26 16:10:03,061 - INFO - Epoch [13/17], Loss: 0.31326186681074464\n",
      "Epoch 14/17: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1043.80it/s]\n",
      "2024-09-26 16:10:04,365 - INFO - Epoch [14/17], Loss: 0.31326186667916706\n",
      "Epoch 15/17: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1038.80it/s]\n",
      "2024-09-26 16:10:05,675 - INFO - Epoch [15/17], Loss: 0.31326186665723743\n",
      "Epoch 16/17: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1051.39it/s]\n",
      "2024-09-26 16:10:06,969 - INFO - Epoch [16/17], Loss: 0.31326186659144867\n",
      "Epoch 17/17: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1014.14it/s]\n",
      "2024-09-26 16:10:08,311 - INFO - Epoch [17/17], Loss: 0.31326186659144867\n",
      "Evaluating: 100%|███████████████████████████| 340/340 [00:00<00:00, 2450.11it/s]\n",
      "[I 2024-09-26 16:10:08,472] Trial 21 finished with value: 100.0 and parameters: {'hidden_size': 250, 'learning_rate': 9.482955939659938e-05, 'batch_size': 23, 'num_epochs': 17}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 977.78it/s]\n",
      "2024-09-26 16:10:10,246 - INFO - Epoch [1/14], Loss: 0.3540507865092437\n",
      "Epoch 2/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 954.04it/s]\n",
      "2024-09-26 16:10:11,672 - INFO - Epoch [2/14], Loss: 0.3142356388133795\n",
      "Epoch 3/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 967.26it/s]\n",
      "2024-09-26 16:10:13,079 - INFO - Epoch [3/14], Loss: 0.31349903033707754\n",
      "Epoch 4/14: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1015.58it/s]\n",
      "2024-09-26 16:10:14,419 - INFO - Epoch [4/14], Loss: 0.31334417986027713\n",
      "Epoch 5/14: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1044.37it/s]\n",
      "2024-09-26 16:10:15,722 - INFO - Epoch [5/14], Loss: 0.31329530220947516\n",
      "Epoch 6/14: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 1036.93it/s]\n",
      "2024-09-26 16:10:17,034 - INFO - Epoch [6/14], Loss: 0.3132766390478374\n",
      "Epoch 7/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 979.67it/s]\n",
      "2024-09-26 16:10:18,423 - INFO - Epoch [7/14], Loss: 0.31326860356102804\n",
      "Epoch 8/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 999.96it/s]\n",
      "2024-09-26 16:10:19,783 - INFO - Epoch [8/14], Loss: 0.3132649930940997\n",
      "Epoch 9/14: 100%|██████████████████████████| 1359/1359 [00:01<00:00, 956.53it/s]\n",
      "2024-09-26 16:10:21,206 - INFO - Epoch [9/14], Loss: 0.31326332530438505\n",
      "Epoch 10/14: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 949.77it/s]\n",
      "2024-09-26 16:10:22,639 - INFO - Epoch [10/14], Loss: 0.3132625333389173\n",
      "Epoch 11/14: 100%|█████████████████████████| 1359/1359 [00:01<00:00, 981.77it/s]\n",
      "2024-09-26 16:10:24,026 - INFO - Epoch [11/14], Loss: 0.3132621587156109\n",
      "Epoch 12/14: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1004.40it/s]\n",
      "2024-09-26 16:10:25,380 - INFO - Epoch [12/14], Loss: 0.313261990164728\n",
      "Epoch 13/14: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1005.94it/s]\n",
      "2024-09-26 16:10:26,733 - INFO - Epoch [13/14], Loss: 0.31326191481463256\n",
      "Epoch 14/14: 100%|████████████████████████| 1359/1359 [00:01<00:00, 1034.36it/s]\n",
      "2024-09-26 16:10:28,048 - INFO - Epoch [14/14], Loss: 0.3132618862842268\n",
      "Evaluating: 100%|███████████████████████████| 340/340 [00:00<00:00, 2768.41it/s]\n",
      "[I 2024-09-26 16:10:28,193] Trial 22 finished with value: 100.0 and parameters: {'hidden_size': 255, 'learning_rate': 1.061370537939199e-05, 'batch_size': 23, 'num_epochs': 14}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/17: 100%|██████████████████████████| 1839/1839 [00:01<00:00, 972.42it/s]\n",
      "2024-09-26 16:10:30,583 - INFO - Epoch [1/17], Loss: 0.3160089200576276\n",
      "Epoch 2/17: 100%|██████████████████████████| 1839/1839 [00:01<00:00, 958.37it/s]\n",
      "2024-09-26 16:10:32,504 - INFO - Epoch [2/17], Loss: 0.31326524591627425\n",
      "Epoch 3/17: 100%|██████████████████████████| 1839/1839 [00:01<00:00, 999.66it/s]\n",
      "2024-09-26 16:10:34,345 - INFO - Epoch [3/17], Loss: 0.3132625304207068\n",
      "Epoch 4/17: 100%|██████████████████████████| 1839/1839 [00:01<00:00, 920.27it/s]\n",
      "2024-09-26 16:10:36,344 - INFO - Epoch [4/17], Loss: 0.3132619863784203\n",
      "Epoch 5/17: 100%|██████████████████████████| 1839/1839 [00:01<00:00, 977.33it/s]\n",
      "2024-09-26 16:10:38,228 - INFO - Epoch [5/17], Loss: 0.31326184425424014\n",
      "Epoch 6/17: 100%|█████████████████████████| 1839/1839 [00:01<00:00, 1074.74it/s]\n",
      "2024-09-26 16:10:39,941 - INFO - Epoch [6/17], Loss: 0.31326181576458123\n",
      "Epoch 7/17: 100%|█████████████████████████| 1839/1839 [00:01<00:00, 1030.71it/s]\n",
      "2024-09-26 16:10:41,727 - INFO - Epoch [7/17], Loss: 0.3132618094443497\n",
      "Epoch 8/17: 100%|█████████████████████████| 1839/1839 [00:01<00:00, 1071.05it/s]\n",
      "2024-09-26 16:10:43,446 - INFO - Epoch [8/17], Loss: 0.3132618077427489\n",
      "Epoch 9/17: 100%|█████████████████████████| 1839/1839 [00:01<00:00, 1068.35it/s]\n",
      "2024-09-26 16:10:45,169 - INFO - Epoch [9/17], Loss: 0.31326180730519443\n",
      "Epoch 10/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1100.87it/s]\n",
      "2024-09-26 16:10:46,842 - INFO - Epoch [10/17], Loss: 0.3132618070621086\n",
      "Epoch 11/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1096.69it/s]\n",
      "2024-09-26 16:10:48,521 - INFO - Epoch [11/17], Loss: 0.31326180699728573\n",
      "Epoch 12/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1053.99it/s]\n",
      "2024-09-26 16:10:50,269 - INFO - Epoch [12/17], Loss: 0.31326180696487427\n",
      "Epoch 13/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1118.06it/s]\n",
      "2024-09-26 16:10:51,915 - INFO - Epoch [13/17], Loss: 0.3132618069324628\n",
      "Epoch 14/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1109.86it/s]\n",
      "2024-09-26 16:10:53,573 - INFO - Epoch [14/17], Loss: 0.3132618069324628\n",
      "Epoch 15/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1070.78it/s]\n",
      "2024-09-26 16:10:55,292 - INFO - Epoch [15/17], Loss: 0.3132618069324628\n",
      "Epoch 16/17: 100%|████████████████████████| 1839/1839 [00:01<00:00, 1072.72it/s]\n",
      "2024-09-26 16:10:57,008 - INFO - Epoch [16/17], Loss: 0.3132618069324628\n",
      "Epoch 17/17: 100%|█████████████████████████| 1839/1839 [00:01<00:00, 992.59it/s]\n",
      "2024-09-26 16:10:58,862 - INFO - Epoch [17/17], Loss: 0.3132618069324628\n",
      "Evaluating: 100%|███████████████████████████| 460/460 [00:00<00:00, 2772.81it/s]\n",
      "[I 2024-09-26 16:10:59,041] Trial 23 finished with value: 100.0 and parameters: {'hidden_size': 238, 'learning_rate': 0.0001288923294122656, 'batch_size': 17, 'num_epochs': 17}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 909.26it/s]\n",
      "2024-09-26 16:11:00,808 - INFO - Epoch [1/12], Loss: 0.31548571361171535\n",
      "Epoch 2/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 941.98it/s]\n",
      "2024-09-26 16:11:02,087 - INFO - Epoch [2/12], Loss: 0.31326299004027575\n",
      "Epoch 3/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 962.82it/s]\n",
      "2024-09-26 16:11:03,339 - INFO - Epoch [3/12], Loss: 0.3132621229239929\n",
      "Epoch 4/12: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 1072.20it/s]\n",
      "2024-09-26 16:11:04,462 - INFO - Epoch [4/12], Loss: 0.3132619469589922\n",
      "Epoch 5/12: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 1048.57it/s]\n",
      "2024-09-26 16:11:05,611 - INFO - Epoch [5/12], Loss: 0.31326189456338793\n",
      "Epoch 6/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 897.10it/s]\n",
      "2024-09-26 16:11:06,954 - INFO - Epoch [6/12], Loss: 0.3132618778166133\n",
      "Epoch 7/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 935.90it/s]\n",
      "2024-09-26 16:11:08,242 - INFO - Epoch [7/12], Loss: 0.31326187182146614\n",
      "Epoch 8/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 826.72it/s]\n",
      "2024-09-26 16:11:09,699 - INFO - Epoch [8/12], Loss: 0.3132618693936793\n",
      "Epoch 9/12: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 916.19it/s]\n",
      "2024-09-26 16:11:11,016 - INFO - Epoch [9/12], Loss: 0.31326186785773247\n",
      "Epoch 10/12: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 980.10it/s]\n",
      "2024-09-26 16:11:12,245 - INFO - Epoch [10/12], Loss: 0.31326186721362576\n",
      "Epoch 11/12: 100%|████████████████████████| 1203/1203 [00:01<00:00, 1029.52it/s]\n",
      "2024-09-26 16:11:13,415 - INFO - Epoch [11/12], Loss: 0.3132618668667991\n",
      "Epoch 12/12: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 915.84it/s]\n",
      "2024-09-26 16:11:14,730 - INFO - Epoch [12/12], Loss: 0.31326186671815903\n",
      "Evaluating: 100%|███████████████████████████| 301/301 [00:00<00:00, 2089.38it/s]\n",
      "[I 2024-09-26 16:11:14,895] Trial 24 finished with value: 100.0 and parameters: {'hidden_size': 226, 'learning_rate': 0.00021681858616972314, 'batch_size': 26, 'num_epochs': 12}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/16: 100%|████████████████████████████| 948/948 [00:01<00:00, 853.30it/s]\n",
      "2024-09-26 16:11:16,285 - INFO - Epoch [1/16], Loss: 0.31391610189454966\n",
      "Epoch 2/16: 100%|████████████████████████████| 948/948 [00:01<00:00, 946.37it/s]\n",
      "2024-09-26 16:11:17,288 - INFO - Epoch [2/16], Loss: 0.3132618975664493\n",
      "Epoch 3/16: 100%|████████████████████████████| 948/948 [00:01<00:00, 945.39it/s]\n",
      "2024-09-26 16:11:18,293 - INFO - Epoch [3/16], Loss: 0.31326189703201945\n",
      "Epoch 4/16: 100%|████████████████████████████| 948/948 [00:00<00:00, 953.96it/s]\n",
      "2024-09-26 16:11:19,288 - INFO - Epoch [4/16], Loss: 0.3132618968119601\n",
      "Epoch 5/16: 100%|████████████████████████████| 948/948 [00:01<00:00, 936.61it/s]\n",
      "2024-09-26 16:11:20,302 - INFO - Epoch [5/16], Loss: 0.3132618965919008\n",
      "Epoch 6/16: 100%|████████████████████████████| 948/948 [00:00<00:00, 964.04it/s]\n",
      "2024-09-26 16:11:21,287 - INFO - Epoch [6/16], Loss: 0.3132618964347155\n",
      "Epoch 7/16: 100%|████████████████████████████| 948/948 [00:00<00:00, 968.08it/s]\n",
      "2024-09-26 16:11:22,268 - INFO - Epoch [7/16], Loss: 0.31326189627753026\n",
      "Epoch 8/16: 100%|████████████████████████████| 948/948 [00:00<00:00, 965.02it/s]\n",
      "2024-09-26 16:11:23,251 - INFO - Epoch [8/16], Loss: 0.31326189627753026\n",
      "Epoch 9/16: 100%|████████████████████████████| 948/948 [00:01<00:00, 936.85it/s]\n",
      "2024-09-26 16:11:24,265 - INFO - Epoch [9/16], Loss: 0.31326189621465617\n",
      "Epoch 10/16: 100%|███████████████████████████| 948/948 [00:00<00:00, 949.37it/s]\n",
      "2024-09-26 16:11:25,266 - INFO - Epoch [10/16], Loss: 0.31326189621465617\n",
      "Epoch 11/16: 100%|███████████████████████████| 948/948 [00:01<00:00, 907.77it/s]\n",
      "2024-09-26 16:11:26,312 - INFO - Epoch [11/16], Loss: 0.31326189621465617\n",
      "Epoch 12/16: 100%|███████████████████████████| 948/948 [00:00<00:00, 968.33it/s]\n",
      "2024-09-26 16:11:27,293 - INFO - Epoch [12/16], Loss: 0.31326189621465617\n",
      "Epoch 13/16: 100%|███████████████████████████| 948/948 [00:01<00:00, 933.01it/s]\n",
      "2024-09-26 16:11:28,310 - INFO - Epoch [13/16], Loss: 0.31326189621465617\n",
      "Epoch 14/16: 100%|███████████████████████████| 948/948 [00:00<00:00, 959.88it/s]\n",
      "2024-09-26 16:11:29,299 - INFO - Epoch [14/16], Loss: 0.31326189621465617\n",
      "Epoch 15/16: 100%|███████████████████████████| 948/948 [00:01<00:00, 927.60it/s]\n",
      "2024-09-26 16:11:30,323 - INFO - Epoch [15/16], Loss: 0.31326189621465617\n",
      "Epoch 16/16: 100%|███████████████████████████| 948/948 [00:01<00:00, 947.32it/s]\n",
      "2024-09-26 16:11:31,325 - INFO - Epoch [16/16], Loss: 0.31326189621465617\n",
      "Evaluating: 100%|███████████████████████████| 237/237 [00:00<00:00, 1927.52it/s]\n",
      "[I 2024-09-26 16:11:31,463] Trial 25 finished with value: 100.0 and parameters: {'hidden_size': 256, 'learning_rate': 0.0015125594123387425, 'batch_size': 33, 'num_epochs': 16}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 891.66it/s]\n",
      "2024-09-26 16:11:32,701 - INFO - Epoch [1/10], Loss: 0.32437726819066204\n",
      "Epoch 2/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 930.44it/s]\n",
      "2024-09-26 16:11:33,587 - INFO - Epoch [2/10], Loss: 0.31333181747254596\n",
      "Epoch 3/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 951.40it/s]\n",
      "2024-09-26 16:11:34,454 - INFO - Epoch [3/10], Loss: 0.31328215778670654\n",
      "Epoch 4/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 958.43it/s]\n",
      "2024-09-26 16:11:35,315 - INFO - Epoch [4/10], Loss: 0.31327053339629096\n",
      "Epoch 5/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 956.83it/s]\n",
      "2024-09-26 16:11:36,177 - INFO - Epoch [5/10], Loss: 0.3132661570175885\n",
      "Epoch 6/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 967.49it/s]\n",
      "2024-09-26 16:11:37,030 - INFO - Epoch [6/10], Loss: 0.3132641456686277\n",
      "Epoch 7/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 934.11it/s]\n",
      "2024-09-26 16:11:37,913 - INFO - Epoch [7/10], Loss: 0.31326313028938135\n",
      "Epoch 8/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 936.18it/s]\n",
      "2024-09-26 16:11:38,794 - INFO - Epoch [8/10], Loss: 0.31326258443250693\n",
      "Epoch 9/10: 100%|████████████████████████████| 823/823 [00:00<00:00, 922.39it/s]\n",
      "2024-09-26 16:11:39,688 - INFO - Epoch [9/10], Loss: 0.31326228514186955\n",
      "Epoch 10/10: 100%|███████████████████████████| 823/823 [00:00<00:00, 987.34it/s]\n",
      "2024-09-26 16:11:40,524 - INFO - Epoch [10/10], Loss: 0.3132621171190556\n",
      "Evaluating: 100%|███████████████████████████| 206/206 [00:00<00:00, 1939.32it/s]\n",
      "[I 2024-09-26 16:11:40,646] Trial 26 finished with value: 100.0 and parameters: {'hidden_size': 210, 'learning_rate': 6.465604994372382e-05, 'batch_size': 38, 'num_epochs': 10}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1079.00it/s]\n",
      "2024-09-26 16:11:42,466 - INFO - Epoch [1/7], Loss: 0.31490742531972843\n",
      "Epoch 2/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1071.50it/s]\n",
      "2024-09-26 16:11:44,004 - INFO - Epoch [2/7], Loss: 0.3132623450543148\n",
      "Epoch 3/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1063.42it/s]\n",
      "2024-09-26 16:11:45,553 - INFO - Epoch [3/7], Loss: 0.31326192999451014\n",
      "Epoch 4/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1075.29it/s]\n",
      "2024-09-26 16:11:47,085 - INFO - Epoch [4/7], Loss: 0.31326185872966145\n",
      "Epoch 5/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1067.36it/s]\n",
      "2024-09-26 16:11:48,629 - INFO - Epoch [5/7], Loss: 0.31326184348448805\n",
      "Epoch 6/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1058.71it/s]\n",
      "2024-09-26 16:11:50,185 - INFO - Epoch [6/7], Loss: 0.3132618387588464\n",
      "Epoch 7/7: 100%|██████████████████████████| 1646/1646 [00:01<00:00, 1061.16it/s]\n",
      "2024-09-26 16:11:51,738 - INFO - Epoch [7/7], Loss: 0.31326183750953884\n",
      "Evaluating: 100%|███████████████████████████| 412/412 [00:00<00:00, 2825.62it/s]\n",
      "[I 2024-09-26 16:11:51,898] Trial 27 finished with value: 100.0 and parameters: {'hidden_size': 231, 'learning_rate': 0.00021488556102504657, 'batch_size': 19, 'num_epochs': 7}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 985.38it/s]\n",
      "2024-09-26 16:11:53,428 - INFO - Epoch [1/13], Loss: 0.31434291511997026\n",
      "Epoch 2/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 956.04it/s]\n",
      "2024-09-26 16:11:54,688 - INFO - Epoch [2/13], Loss: 0.3132627643056443\n",
      "Epoch 3/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 993.18it/s]\n",
      "2024-09-26 16:11:55,901 - INFO - Epoch [3/13], Loss: 0.313262036489826\n",
      "Epoch 4/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 999.26it/s]\n",
      "2024-09-26 16:11:57,106 - INFO - Epoch [4/13], Loss: 0.3132618933494945\n",
      "Epoch 5/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 949.07it/s]\n",
      "2024-09-26 16:11:58,376 - INFO - Epoch [5/13], Loss: 0.31326187149941276\n",
      "Epoch 6/13: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 1024.57it/s]\n",
      "2024-09-26 16:11:59,553 - INFO - Epoch [6/13], Loss: 0.3132618680311458\n",
      "Epoch 7/13: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 1010.24it/s]\n",
      "2024-09-26 16:12:00,750 - INFO - Epoch [7/13], Loss: 0.3132618672383991\n",
      "Epoch 8/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 974.51it/s]\n",
      "2024-09-26 16:12:01,986 - INFO - Epoch [8/13], Loss: 0.3132618668172524\n",
      "Epoch 9/13: 100%|██████████████████████████| 1203/1203 [00:01<00:00, 989.69it/s]\n",
      "2024-09-26 16:12:03,204 - INFO - Epoch [9/13], Loss: 0.3132618666190657\n",
      "Epoch 10/13: 100%|████████████████████████| 1203/1203 [00:01<00:00, 1045.69it/s]\n",
      "2024-09-26 16:12:04,356 - INFO - Epoch [10/13], Loss: 0.3132618665447457\n",
      "Epoch 11/13: 100%|████████████████████████| 1203/1203 [00:01<00:00, 1059.34it/s]\n",
      "2024-09-26 16:12:05,493 - INFO - Epoch [11/13], Loss: 0.3132618665199724\n",
      "Epoch 12/13: 100%|████████████████████████| 1203/1203 [00:01<00:00, 1064.97it/s]\n",
      "2024-09-26 16:12:06,624 - INFO - Epoch [12/13], Loss: 0.3132618665199724\n",
      "Epoch 13/13: 100%|█████████████████████████| 1203/1203 [00:01<00:00, 950.02it/s]\n",
      "2024-09-26 16:12:07,893 - INFO - Epoch [13/13], Loss: 0.3132618664704257\n",
      "Evaluating: 100%|███████████████████████████| 301/301 [00:00<00:00, 1999.10it/s]\n",
      "[I 2024-09-26 16:12:08,066] Trial 28 finished with value: 100.0 and parameters: {'hidden_size': 205, 'learning_rate': 0.0004859509057528671, 'batch_size': 26, 'num_epochs': 13}. Best is trial 0 with value: 100.0.\n",
      "/tmp/ipykernel_13563/3527472803.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "Epoch 1/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 676.87it/s]\n",
      "2024-09-26 16:12:09,318 - INFO - Epoch [1/9], Loss: 0.319860026184118\n",
      "Epoch 2/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 741.55it/s]\n",
      "2024-09-26 16:12:10,034 - INFO - Epoch [2/9], Loss: 0.31328755920788026\n",
      "Epoch 3/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 770.90it/s]\n",
      "2024-09-26 16:12:10,723 - INFO - Epoch [3/9], Loss: 0.31327013603921205\n",
      "Epoch 4/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 812.41it/s]\n",
      "2024-09-26 16:12:11,377 - INFO - Epoch [4/9], Loss: 0.3132657490811258\n",
      "Epoch 5/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 530.12it/s]\n",
      "2024-09-26 16:12:12,378 - INFO - Epoch [5/9], Loss: 0.31326398630187197\n",
      "Epoch 6/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 717.93it/s]\n",
      "2024-09-26 16:12:13,118 - INFO - Epoch [6/9], Loss: 0.3132631075832079\n",
      "Epoch 7/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 770.72it/s]\n",
      "2024-09-26 16:12:13,807 - INFO - Epoch [7/9], Loss: 0.3132626178691972\n",
      "Epoch 8/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 867.48it/s]\n",
      "2024-09-26 16:12:14,420 - INFO - Epoch [8/9], Loss: 0.31326232501920664\n",
      "Epoch 9/9: 100%|█████████████████████████████| 530/530 [00:00<00:00, 841.80it/s]\n",
      "2024-09-26 16:12:15,051 - INFO - Epoch [9/9], Loss: 0.3132621388952687\n",
      "Evaluating: 100%|███████████████████████████| 133/133 [00:00<00:00, 1804.04it/s]\n",
      "[I 2024-09-26 16:12:15,139] Trial 29 finished with value: 100.0 and parameters: {'hidden_size': 180, 'learning_rate': 0.00016868825962935784, 'batch_size': 59, 'num_epochs': 9}. Best is trial 0 with value: 100.0.\n",
      "2024-09-26 16:12:15,146 - INFO - Best trial: 100.0\n",
      "2024-09-26 16:12:15,147 - INFO - Best parameters: {'hidden_size': 225, 'learning_rate': 0.0031717893605886192, 'batch_size': 62, 'num_epochs': 7}\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "logging.info(f\"Best trial: {study.best_trial.value}\")\n",
    "logging.info(f\"Best parameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f750cca9-680b-473d-b71d-bc0dafb90b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with the best parameters\n",
    "best_hidden_size = study.best_trial.params['hidden_size']\n",
    "best_learning_rate = study.best_trial.params['learning_rate']\n",
    "best_batch_size = study.best_trial.params['batch_size']\n",
    "best_num_epochs = study.best_trial.params['num_epochs']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
    "\n",
    "X = np.array(df['embeddings'].tolist())\n",
    "y = np.array(df['class_encoded'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a03824e-2136-4a33-8c53-4f4724a989d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 885.88it/s]\n",
      "2024-09-26 16:12:29,822 - INFO - Epoch [1/7], Loss: 0.31407951742115586\n",
      "Epoch 2/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 910.75it/s]\n",
      "2024-09-26 16:12:30,379 - INFO - Epoch [2/7], Loss: 0.3132618673367075\n",
      "Epoch 3/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 919.34it/s]\n",
      "2024-09-26 16:12:30,930 - INFO - Epoch [3/7], Loss: 0.31326186662853356\n",
      "Epoch 4/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 888.64it/s]\n",
      "2024-09-26 16:12:31,499 - INFO - Epoch [4/7], Loss: 0.31326186639247555\n",
      "Epoch 5/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 924.13it/s]\n",
      "2024-09-26 16:12:32,047 - INFO - Epoch [5/7], Loss: 0.31326186633346104\n",
      "Epoch 6/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 913.04it/s]\n",
      "2024-09-26 16:12:32,602 - INFO - Epoch [6/7], Loss: 0.31326186633346104\n",
      "Epoch 7/7: 100%|█████████████████████████████| 505/505 [00:00<00:00, 795.80it/s]\n",
      "2024-09-26 16:12:33,238 - INFO - Epoch [7/7], Loss: 0.31326186633346104\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(y_train))\n",
    "model = EmbeddingClassifier(input_size=input_size, hidden_size=best_hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, best_num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc23b06-c1f1-4eae-8848-5a4c203dff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 16:12:33,268 - INFO - Model saved as 'best_model.pth'\n",
      "2024-09-26 16:12:33,269 - INFO - Hyperparameters saved as 'hyperparameters.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "torch.save(model.state_dict(), 'best_model.pth')\n",
    "logging.info(\"Model saved as 'best_model.pth'\")\n",
    "\n",
    "# Save hyperparameters to a JSON file\n",
    "hyperparameters = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": best_hidden_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"learning_rate\": best_learning_rate,\n",
    "    \"batch_size\": best_batch_size,\n",
    "    \"num_epochs\": best_num_epochs\n",
    "}\n",
    "with open('hyperparameters.json', 'w') as f:\n",
    "    json.dump(hyperparameters, f)\n",
    "logging.info(\"Hyperparameters saved as 'hyperparameters.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ecec2-caf5-4dee-a634-565a99d0aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69459cf-fc30-4457-81d3-9da698f07596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17382aa8-4b8d-4f90-93b7-06f3b53c3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13563/281122150.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "input_size = 768\n",
    "hidden_size = 225\n",
    "output_size = 2  \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "model = EmbeddingClassifier(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()  \n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, y_pred = torch.max(outputs, dim=1)  \n",
    "\n",
    "y_pred_np = y_pred.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "f1 = f1_score(y_test_np, y_pred_np, average='weighted') \n",
    "precision = precision_score(y_test_np, y_pred_np, average='weighted')\n",
    "recall = recall_score(y_test_np, y_pred_np, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2172829-566b-4cbe-a43f-43bbc5a04502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAIhCAYAAAD91lq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABaW0lEQVR4nO3deVxU9f7H8ffIpqJMArKZuevVsNwK4VbuWy6VlWukZVppmldNr5mJZaJ2c7lZZmaipmm3tLKMtFy6piiSlFuWppm/QFwQQwkQzu8Pf55fE1hwcpyReT17zOMh3/OdM5+Ze8lP7+/3nLEZhmEIAAAAKKVyri4AAAAA1yYaSQAAAFhCIwkAAABLaCQBAABgCY0kAAAALKGRBAAAgCU0kgAAALCERhIAAACW0EgCAADAEhpJ4BrwzTff6KGHHlKtWrVUvnx5VapUSc2aNdOMGTN0+vRpp772rl271KpVK9ntdtlsNs2ePfuKv4bNZlNcXNwVP++fSUhIkM1mk81m06ZNm4ocNwxDdevWlc1mU+vWrS29xquvvqqEhIRSPWfTpk2XrQkA3Im3qwsA8McWLFigoUOHqkGDBnrqqafUqFEj5efna+fOnXrttde0bds2rV692mmv//DDD+vcuXNasWKFqlSpopo1a17x19i2bZuuv/76K37ekqpcubIWLlxYpFncvHmzDh06pMqVK1s+96uvvqrg4GANHDiwxM9p1qyZtm3bpkaNGll+XQC4GmgkATe2bds2Pf744+rQoYPef/99+fn5mcc6dOig0aNHKzEx0ak17NmzR4MHD1aXLl2c9hotW7Z02rlLonfv3lq2bJleeeUVBQQEmOMLFy5UdHS0zp49e1XqyM/Pl81mU0BAgMs/EwAoCZa2ATc2depU2Ww2vf766w5N5CW+vr7q0aOH+XNhYaFmzJihv/3tb/Lz81NISIgefPBBHTt2zOF5rVu3VmRkpJKTk3X77berYsWKql27tqZNm6bCwkJJ/7/se+HCBc2bN89cApakuLg488+/dek5R44cMcc2bNig1q1bKygoSBUqVNANN9yge++9V+fPnzfnFLe0vWfPHt11112qUqWKypcvryZNmmjx4sUOcy4tAb/99tuaMGGCIiIiFBAQoPbt2+vAgQMl+5Al9e3bV5L09ttvm2NZWVl677339PDDDxf7nMmTJysqKkqBgYEKCAhQs2bNtHDhQhmGYc6pWbOm9u7dq82bN5uf36VE91LtS5cu1ejRo1WtWjX5+fnp4MGDRZa2T548qerVqysmJkb5+fnm+fft2yd/f3/FxsaW+L0CwJVEIwm4qYKCAm3YsEHNmzdX9erVS/Scxx9/XOPGjVOHDh304Ycf6vnnn1diYqJiYmJ08uRJh7np6enq37+/HnjgAX344Yfq0qWLxo8fr7feekuS1LVrV23btk2SdN9992nbtm3mzyV15MgRde3aVb6+vnrzzTeVmJioadOmyd/fX3l5eZd93oEDBxQTE6O9e/fq3//+t1atWqVGjRpp4MCBmjFjRpH5Tz/9tH788Ue98cYbev311/X999+re/fuKigoKFGdAQEBuu+++/Tmm2+aY2+//bbKlSun3r17X/a9Pfroo3rnnXe0atUq9ezZU8OHD9fzzz9vzlm9erVq166tpk2bmp/f77chjB8/XkePHtVrr72mNWvWKCQkpMhrBQcHa8WKFUpOTta4ceMkSefPn9f999+vG264Qa+99lqJ3icAXHEGALeUnp5uSDL69OlTovn79+83JBlDhw51GN++fbshyXj66afNsVatWhmSjO3btzvMbdSokdGpUyeHMUnGsGHDHMYmTZpkFPevj0WLFhmSjMOHDxuGYRjvvvuuIclITU39w9olGZMmTTJ/7tOnj+Hn52ccPXrUYV6XLl2MihUrGmfOnDEMwzA2btxoSDLuvPNOh3nvvPOOIcnYtm3bH77upXqTk5PNc+3Zs8cwDMO45ZZbjIEDBxqGYRg33nij0apVq8uep6CgwMjPzzeee+45IygoyCgsLDSPXe65l17vjjvuuOyxjRs3OoxPnz7dkGSsXr3aGDBggFGhQgXjm2+++cP3CADORCIJlBEbN26UpCIXddx6661q2LChPv/8c4fxsLAw3XrrrQ5jN910k3788ccrVlOTJk3k6+urIUOGaPHixfrhhx9K9LwNGzaoXbt2RZLYgQMH6vz580WS0d8u70sX34ekUr2XVq1aqU6dOnrzzTe1e/duJScnX3ZZ+1KN7du3l91ul5eXl3x8fPTss8/q1KlTysjIKPHr3nvvvSWe+9RTT6lr167q27evFi9erJdfflmNGzcu8fMB4EqjkQTcVHBwsCpWrKjDhw+XaP6pU6ckSeHh4UWORUREmMcvCQoKKjLPz89POTk5FqotXp06dfTZZ58pJCREw4YNU506dVSnTh3NmTPnD5936tSpy76PS8d/6/fv5dJ+0tK8F5vNpoceekhvvfWWXnvtNdWvX1+33357sXN37Nihjh07Srp4Vf2XX36p5ORkTZgwodSvW9z7/KMaBw4cqF9//VVhYWHsjQTgcjSSgJvy8vJSu3btlJKSUuRimeJcaqbS0tKKHPv5558VHBx8xWorX768JCk3N9dh/Pf7MCXp9ttv15o1a5SVlaWkpCRFR0dr5MiRWrFixWXPHxQUdNn3IemKvpffGjhwoE6ePKnXXntNDz300GXnrVixQj4+Pvroo4/Uq1cvxcTEqEWLFpZes7iLli4nLS1Nw4YNU5MmTXTq1CmNGTPG0msCwJVCIwm4sfHjx8swDA0ePLjYi1Py8/O1Zs0aSVLbtm0lybxY5pLk5GTt379f7dq1u2J1Xbry+JtvvnEYv1RLcby8vBQVFaVXXnlFkvTVV19ddm67du20YcMGs3G8ZMmSJapYsaLTbo1TrVo1PfXUU+revbsGDBhw2Xk2m03e3t7y8vIyx3JycrR06dIic69UyltQUKC+ffvKZrPpk08+UXx8vF5++WWtWrXqL58bAKziPpKAG4uOjta8efM0dOhQNW/eXI8//rhuvPFG5efna9euXXr99dcVGRmp7t27q0GDBhoyZIhefvlllStXTl26dNGRI0c0ceJEVa9eXf/4xz+uWF133nmnAgMDNWjQID333HPy9vZWQkKCfvrpJ4d5r732mjZs2KCuXbvqhhtu0K+//mpeGd2+ffvLnn/SpEn66KOP1KZNGz377LMKDAzUsmXL9PHHH2vGjBmy2+1X7L383rRp0/50TteuXTVz5kz169dPQ4YM0alTp/Svf/2r2Fs0NW7cWCtWrNDKlStVu3ZtlS9f3tK+xkmTJum///2v1q1bp7CwMI0ePVqbN2/WoEGD1LRpU9WqVavU5wSAv4pGEnBzgwcP1q233qpZs2Zp+vTpSk9Pl4+Pj+rXr69+/frpiSeeMOfOmzdPderU0cKFC/XKK6/Ibrerc+fOio+PL3ZPpFUBAQFKTEzUyJEj9cADD+i6667TI488oi5duuiRRx4x5zVp0kTr1q3TpEmTlJ6erkqVKikyMlIffvihucewOA0aNNDWrVv19NNPa9iwYcrJyVHDhg21aNGiUn1DjLO0bdtWb775pqZPn67u3burWrVqGjx4sEJCQjRo0CCHuZMnT1ZaWpoGDx6sX375RTVq1HC4z2ZJrF+/XvHx8Zo4caJDspyQkKCmTZuqd+/e2rJli3x9fa/E2wOAErMZxm/ungsAAACUEHskAQAAYAmNJAAAACyhkQQAAIAlNJIAAACwhEYSAADATcXHx8tms2nkyJHmmGEYiouLU0REhCpUqKDWrVtr7969Ds/Lzc3V8OHDFRwcLH9/f/Xo0aPIl1tkZmYqNjZWdrtddrtdsbGxOnPmTKnqo5EEAABwQ8nJyXr99dd10003OYzPmDFDM2fO1Ny5c5WcnKywsDB16NBBv/zyizln5MiRWr16tVasWKEtW7YoOztb3bp1U0FBgTmnX79+Sk1NVWJiohITE5Wamlrqr17l9j8AAABuJjs7W82aNdOrr76qKVOmqEmTJpo9e7YMw1BERIRGjhypcePGSbqYPoaGhmr69Ol69NFHlZWVpapVq2rp0qXq3bu3pItfMVu9enWtXbtWnTp10v79+9WoUSMlJSUpKipKksyvsf3222/VoEGDEtVZJm9IXqHpE38+CcA1KTN5rqtLAOAk5V3YlTizdziT9JJyc3Mdxvz8/Ir9NqxLhg0bpq5du6p9+/aaMmWKOX748GGlp6c7fKmDn5+fWrVqpa1bt+rRRx9VSkqK8vPzHeZEREQoMjJSW7duVadOnbRt2zbZ7XaziZSkli1bym63a+vWrSVuJFnaBgAAcKL4+HhzH+KlR3x8/GXnr1ixQl999VWxc9LT0yVJoaGhDuOhoaHmsfT0dPn6+qpKlSp/OCckJKTI+UNCQsw5JVEmE0kAAIBSsTkvWxs/frxGjRrlMHa5NPKnn37Sk08+qXXr1ql8+fKXPafNZnP42TCMImO/9/s5xc0vyXl+i0QSAADAZnPaw8/PTwEBAQ6PyzWSKSkpysjIUPPmzeXt7S1vb29t3rxZ//73v+Xt7W0mkb9PDTMyMsxjYWFhysvLU2Zm5h/OOX78eJHXP3HiRJG084/QSAIAALiJdu3aaffu3UpNTTUfLVq0UP/+/ZWamqratWsrLCxM69evN5+Tl5enzZs3KyYmRpLUvHlz+fj4OMxJS0vTnj17zDnR0dHKysrSjh07zDnbt29XVlaWOackWNoGAABw4tJ2aVSuXFmRkZEOY/7+/goKCjLHR44cqalTp6pevXqqV6+epk6dqooVK6pfv36SJLvdrkGDBmn06NEKCgpSYGCgxowZo8aNG6t9+/aSpIYNG6pz584aPHiw5s+fL0kaMmSIunXrVuILbSQaSQAAgGvK2LFjlZOTo6FDhyozM1NRUVFat26dKleubM6ZNWuWvL291atXL+Xk5Khdu3ZKSEiQl5eXOWfZsmUaMWKEeXV3jx49NHdu6e6MUSbvI8ntf4Cyi9v/AGWXS2//c8uoP59kUU7yTKed29XcI8cFAADANYelbQAAADfZI3mt4VMDAACAJSSSAAAApbgJN/4fjSQAAABL25bwqQEAAMASEkkAAACWti0hkQQAAIAlJJIAAADskbSETw0AAACWkEgCAACwR9ISEkkAAABYQiIJAADAHklLaCQBAABY2raE9hsAAACWkEgCAACwtG0JnxoAAAAsIZEEAAAgkbSETw0AAACWkEgCAACU46ptK0gkAQAAYAmJJAAAAHskLaGRBAAA4IbkltB+AwAAwBISSQAAAJa2LeFTAwAAgCUkkgAAAOyRtIREEgAAAJaQSAIAALBH0hI+NQAAAFhCIgkAAMAeSUtoJAEAAFjatoRPDQAAAJaQSAIAALC0bQmJJAAAACwhkQQAAGCPpCV8agAAALCERBIAAIA9kpaQSAIAAMASEkkAAAD2SFpCIwkAAEAjaQmfGgAAACwhkQQAAOBiG0tIJAEAAGAJiSQAAAB7JC3hUwMAAIAlJJIAAADskbSERBIAAMBNzJs3TzfddJMCAgIUEBCg6OhoffLJJ+bxgQMHymazOTxatmzpcI7c3FwNHz5cwcHB8vf3V48ePXTs2DGHOZmZmYqNjZXdbpfdbldsbKzOnDlT6nppJAEAAGzlnPcoheuvv17Tpk3Tzp07tXPnTrVt21Z33XWX9u7da87p3Lmz0tLSzMfatWsdzjFy5EitXr1aK1as0JYtW5Sdna1u3bqpoKDAnNOvXz+lpqYqMTFRiYmJSk1NVWxsbKk/Npa2AQAA3GRpu3v37g4/v/DCC5o3b56SkpJ04403SpL8/PwUFhZW7POzsrK0cOFCLV26VO3bt5ckvfXWW6pevbo+++wzderUSfv371diYqKSkpIUFRUlSVqwYIGio6N14MABNWjQoMT1kkgCAAA4UW5urs6ePevwyM3N/dPnFRQUaMWKFTp37pyio6PN8U2bNikkJET169fX4MGDlZGRYR5LSUlRfn6+OnbsaI5FREQoMjJSW7dulSRt27ZNdrvdbCIlqWXLlrLb7eackqKRBAAAHu/3+w6v5CM+Pt7ci3jpER8ff9ladu/erUqVKsnPz0+PPfaYVq9erUaNGkmSunTpomXLlmnDhg166aWXlJycrLZt25qNaXp6unx9fVWlShWHc4aGhio9Pd2cExISUuR1Q0JCzDklxdI2AACAE40fP16jRo1yGPPz87vs/AYNGig1NVVnzpzRe++9pwEDBmjz5s1q1KiRevfubc6LjIxUixYtVKNGDX388cfq2bPnZc9pGIZsv1m+txWzlP/7OSVBIwkAADxeaRuo0vDz8/vDxvH3fH19VbduXUlSixYtlJycrDlz5mj+/PlF5oaHh6tGjRr6/vvvJUlhYWHKy8tTZmamQyqZkZGhmJgYc87x48eLnOvEiRMKDQ0t1XtjaRsAAMCNGYZx2T2Vp06d0k8//aTw8HBJUvPmzeXj46P169ebc9LS0rRnzx6zkYyOjlZWVpZ27Nhhztm+fbuysrLMOSVFIgkAAOAeF23r6aefVpcuXVS9enX98ssvWrFihTZt2qTExERlZ2crLi5O9957r8LDw3XkyBE9/fTTCg4O1j333CNJstvtGjRokEaPHq2goCAFBgZqzJgxaty4sXkVd8OGDdW5c2cNHjzYTDmHDBmibt26leqKbYlGEgAAwG0cP35csbGxSktLk91u10033aTExER16NBBOTk52r17t5YsWaIzZ84oPDxcbdq00cqVK1W5cmXzHLNmzZK3t7d69eqlnJwctWvXTgkJCfLy8jLnLFu2TCNGjDCv7u7Ro4fmzp1b6npthmEYf/1tu5cKTZ9wdQkAnCQzufT/ogNwbSjvwnirUq8Ep507+52BTju3q5FIAgAAj+fMi23KMi62AQAAgCUkkgAAwOORSFpDIgkAAABLSCQBAIDHI5G0hkQSAAAAlpBIAgAAEEhaQiIJAAAAS0gkAQCAx2OPpDUkkgAAALCERBIAAHg8EklraCQBAIDHo5G0hqVtAAAAWEIiCQAAPB6JpDUkkgAAALCERBIAAIBA0hISSQAAAFhCIgkAADweeyStIZEEAACAJW7RSD733HM6f/58kfGcnBw999xzLqgIAAB4EpvN5rRHWeYWjeTkyZOVnZ1dZPz8+fOaPHmyCyoCAACehEbSGrdoJA3DKPaD/vrrrxUYGOiCigAAAPBnXHqxTZUqVcxuvX79+g7NZEFBgbKzs/XYY4+5sEIAAOARynZw6DQubSRnz54twzD08MMPa/LkybLb7eYxX19f1axZU9HR0S6sEAAAAJfj0kZywIABkqRatWopJiZGPj4+riwHAAB4qLK+l9FZ3OI+kq1atVJhYaG+++47ZWRkqLCw0OH4HXfc4aLKAAAAcDlu0UgmJSWpX79++vHHH2UYhsMxm82mgoICF1UGAAA8AYmkNW7RSD722GNq0aKFPv74Y4WHh/M/JgAAwDXALRrJ77//Xu+++67q1q3r6lIAAIAHIsSyxi3uIxkVFaWDBw+6ugwAAOChuCG5NW6RSA4fPlyjR49Wenq6GjduXOTq7ZtuuslFlQEAAOBy3KKRvPfeeyVJDz/8sDlms9nMb7zhYhsAAOBUZTs4dBq3aCQPHz7s6hIAAABQSm7RSNaoUcPVJQAAAA9W1vcyOotbNJKX7Nu3T0ePHlVeXp7DeI8ePVxUEQAAAC7HLRrJH374Qffcc492795t7o2U/v+/DtgjCQAAnIlE0hq3uP3Pk08+qVq1aun48eOqWLGi9u7dqy+++EItWrTQpk2bXF0eAAAAiuEWieS2bdu0YcMGVa1aVeXKlVO5cuV02223KT4+XiNGjNCuXbtcXSIAACjDSCStcYtEsqCgQJUqVZIkBQcH6+eff5Z08SKcAwcOuLI0AADgCWxOfJRhbpFIRkZG6ptvvlHt2rUVFRWlGTNmyNfXV6+//rpq167t6vIAAABQDLdoJJ955hmdO3dOkjRlyhR169ZNt99+u4KCgrRy5UoXVwcAAMo6lratcYtGslOnTuafa9eurX379un06dOqUqUK/8MCAAC4KbfYI7l48WIzkbwkMDCQJhIAAFwVNpvNaY+yzC0ayTFjxigkJER9+vTRRx99pAsXLri6JAAAAPwJt2gk09LStHLlSnl5ealPnz4KDw/X0KFDtXXrVleXhqtszMMdlbNrrl4cc6/D+IRH79QP617Q6W0z9emCJ9WwdpjD8Yd7/l2fLnhSx//7onJ2zZW9UoUi5/7P7Ef13drnlJk0Sz+se0ELn39Q4VXtTn0/AKxb+fYydenYVrc0baw+9/fUVyk7XV0SyjASSWvcopH09vZWt27dtGzZMmVkZGj27Nn68ccf1aZNG9WpU8fV5eEqad7oBg3qGaNvvjvmMD56YHuNeKCN/jHtHd32wIs6fuqsPn5tuCpV9DPnVCzvo/Vb9+nFN9dd9vxfJH+nB8a9qZvveU79nnpDtasHa/mLg5z2fgBYl/jJWs2YFq/BQx7XynffV7NmzTX00cFK+7/bwwFwD27RSP5WxYoV1alTJ3Xp0kX16tXTkSNHXF0SrgL/Cr5aNHWghj7/ts6czXE4NqxfG81Y+Kk+2PC19h1K0yMTl6pCeR/17tLCnDN3+Sb9a9F6bf/myGVf4+VlG7Vj9xEdTctU0teH9a9F63Vr45ry9na7XwPA4y1dvEj33Huvet53v2rXqaOx4ycoLDxM76x829WloYxyl0Ry3rx5uummmxQQEKCAgABFR0frk08+MY8bhqG4uDhFRESoQoUKat26tfbu3etwjtzcXA0fPlzBwcHy9/dXjx49dOyYY0iTmZmp2NhY2e122e12xcbG6syZM6X+3Nzmb9Dz589r2bJluvPOOxUREaFZs2bp7rvv1p49e1xdGq6C2eN7K/G/e7Rxu+MN6GtWC1J4Vbs+2/atOZaXf0H/TTmoljdbv8dolYCK6tOlhZK+PqwLFwotnwfAlZefl6f9+/YqOuY2h/HomL/r61S+6QxO4iY3JL/++us1bdo07dy5Uzt37lTbtm111113mc3ijBkzNHPmTM2dO1fJyckKCwtThw4d9Msvv5jnGDlypFavXq0VK1Zoy5Ytys7OVrdu3VRQUGDO6devn1JTU5WYmKjExESlpqYqNja2lB+am9z+p2/fvlqzZo0qVqyo+++/X5s2bVJMTEyJnpubm6vc3FyHMaOwQLZyXs4oFU5wf6fmavK36rrtgRlFjoUFB0iSMk7/4jCeceoX3RAeWOrXmjLiLj3W5w75V/DT9m8Oq+eI16wVDcBpMs9kqqCgQEFBQQ7jQUHBOnnyhIuqAq6O7t27O/z8wgsvaN68eUpKSlKjRo00e/ZsTZgwQT179pR08c43oaGhWr58uR599FFlZWVp4cKFWrp0qdq3by9Jeuutt1S9enV99tln6tSpk/bv36/ExEQlJSUpKipKkrRgwQJFR0frwIEDatCgQYnrdYtE0mazaeXKlfr555/1yiuvlLiJlKT4+Hgzlr30uHA8xYnV4kq6PvQ6vfjUvXr4mcXKzbv81fqGYTj8bLMVHSuJWUs+U8s+09X1sbkqKCjUG8+X/r++AFwdv18SNAyjzF+4ANdx5tJ2bm6uzp496/D4fQhWnIKCAq1YsULnzp1TdHS0Dh8+rPT0dHXs2NGc4+fnp1atWpkXKKekpCg/P99hTkREhCIjI80527Ztk91uN5tISWrZsqXsdnupL3R2i0Zy+fLl6tq1q7y9vfXrr7+W6rnjx49XVlaWw8M7tLmTKsWV1rThDQoNCtDWZWP1S/Ic/ZI8R3e0qKehfVvpl+Q5On7qYhIZGhTg8LyqgZWLpJQlcerMOR08mqEN27/Vg/9cpC63RyrqplpX5L0AuDKqXFdFXl5eOnnypMP46dOnFBQU7KKqAOuKC73i4+MvO3/37t2qVKmS/Pz89Nhjj2n16tVq1KiR0tPTJUmhoaEO80NDQ81j6enp8vX1VZUqVf5wTkhISJHXDQkJMeeUlFssbRcWFuqFF17Qa6+9puPHj+u7775T7dq1NXHiRNWsWVODBl3+ylo/Pz/5+fk5jLGsfe3YuOOAmt/3gsPY65Mf0IHDx/VSwnodPnZSaSey1K7l3/T1gYsbhX28vXR787p6Zs4Hf+m1LwUbvj5u8WsA4P/4+PqqYaMblbT1S7Vr38EcT9q6Va3btnNhZSjLnJl2jx8/XqNGjXIY+33v8lsNGjRQamqqzpw5o/fee08DBgzQ5s2bL1trSdL6388pbr6V1N8t/gadMmWKFi9erBkzZmjw4MHmeOPGjTVr1qw/bCRxbcs+n6t9h9Icxs7l5Ol01jlz/JXlG/XUoI46eDRDB4+e0NhBnZTza75WfvL/95QLDaqs0KAA1bnhYloRWS9Cv5z7VT+lZyrz7Hm1uLGGWkTW0NZdh3Tml/OqWS1Yzz7eVYeOntD2bw5fvTcMoERiBzykCf8cq0aRkbr55qZ67z8rlZaWpvt793F1aUCpFRd6/RFfX1/VrVtXktSiRQslJydrzpw5GjdunKSLiWJ4eLg5PyMjw0wpw8LClJeXp8zMTIdUMiMjw9w6GBYWpuPHjxd53RMnThRJO/+MWzSSS5Ys0euvv6527drpscceM8dvuukmffvtt3/wTHiClxI+U3k/X80e31tVAioqec8RdXt8rrLP///+kkfuu13PPHan+fNnb/5DkjT42aV6a8125eTm6662N+uZx7rKv4Kv0k9mad3W/Xrwn4uUl883KQHupnOXO5V1JlOvz3tVJ05kqG69+nrltdcVEVHN1aWhjHLn7beGYSg3N1e1atVSWFiY1q9fr6ZNm0qS8vLytHnzZk2fPl2S1Lx5c/n4+Gj9+vXq1auXpItf/LJnzx7NmHHxotbo6GhlZWVpx44duvXWWyVJ27dvV1ZWVqmuU5Ekm2HlioUrrEKFCvr2229Vo0YNVa5cWV9//bVq166tffv26dZbb1V2dnbpztf0CSdVCsDVMpPnuroEAE5S3oXxVt0xn/z5JIsO/qtLiec+/fTT6tKli6pXr65ffvlFK1as0LRp05SYmKgOHTpo+vTpio+P16JFi1SvXj1NnTpVmzZt0oEDB1S5cmVJ0uOPP66PPvpICQkJCgwM1JgxY3Tq1CmlpKTIy+vi9r8uXbro559/1vz58yVJQ4YMUY0aNbRmzZpSvTe3SCRvvPFG/fe//1WNGjUcxv/zn/+YHTcAAICzuMsdAY4fP67Y2FilpaXJbrfrpptuMptISRo7dqxycnI0dOhQZWZmKioqSuvWrTObSEmaNWuWvL291atXL+Xk5Khdu3ZKSEgwm0hJWrZsmUaMGGFe3d2jRw/NnVv6/1B3i0RyzZo1io2N1fjx4/Xcc89p8uTJOnDggJYsWaKPPvrI/PBKikQSKLtIJIGyy5WJZP2xiU4793czOjvt3K7mFrf/6d69u1auXKm1a9fKZrPp2Wef1f79+7VmzZpSN5EAAAC4OtxiaVuSOnXqpE6dOrm6DAAA4IHcZWn7WuMWiSQAAACuPS5LJKtUqVLi7v/06dNOrgYAAHgyAklrXNZIzp4921UvDQAAgCvAZY3kgAEDXPXSAAAADsqVI5K0wm32SB46dEjPPPOM+vbtq4yMDElSYmKi9u7d6+LKAAAAUBy3aCQ3b96sxo0ba/v27Vq1apX5TTbffPONJk2a5OLqAABAWWezOe9RlrlFI/nPf/5TU6ZM0fr16+Xr62uOt2nTRtu2bXNhZQAAwBPYbDanPcoyt2gkd+/erXvuuafIeNWqVXXq1CkXVAQAAIA/4xaN5HXXXae0tLQi47t27VK1atVcUBEAAPAkLG1b4xaNZL9+/TRu3Dilp6fLZrOpsLBQX375pcaMGaMHH3zQ1eUBAACgGG7RSL7wwgu64YYbVK1aNWVnZ6tRo0a64447FBMTo2eeecbV5QEAgDKOPZLWuPy7tg3D0M8//6wFCxbo+eef11dffaXCwkI1bdpU9erVc3V5AAAAuAy3aCTr1aunvXv3ql69eqpdu7arSwIAAB6mrCeHzuLype1y5cqpXr16XJ0NAABwjXF5IylJM2bM0FNPPaU9e/a4uhQAAOCBuGrbGpcvbUvSAw88oPPnz+vmm2+Wr6+vKlSo4HD89OnTLqoMAAB4Apa2rXGLRnL27NmuLgEAAACl5PJGMj8/X5s2bdLEiRO50AYAALgEgaQ1Lt8j6ePjo9WrV7u6DAAAAJSSyxtJSbrnnnv0/vvvu7oMAADgobghuTUuX9qWpLp16+r555/X1q1b1bx5c/n7+zscHzFihIsqAwAAwOW4RSP5xhtv6LrrrlNKSopSUlIcjtlsNhpJAADgVGU8OHQat2gkDx8+7OoSAAAAUEouayRHjRql559/Xv7+/ho1atRl59lsNr300ktXsTIAAOBpyvpeRmdxWSO5a9cu5efnm3++HP6HBQAAcE8uayQ3btxY7J8BAACuNnIra9xijyQAAIArsQJqjVvcRxIAAADXHhJJAADg8QgkrSGRBAAAgCUkkgAAwOOxR9IaEkkAAABYQiIJAAA8HoGkNSSSAAAAsIREEgAAeDz2SFpDIwkAADwefaQ1LG0DAADAEhJJAADg8VjatoZEEgAAAJaQSAIAAI9HImkNiSQAAAAsIZEEAAAej0DSGhJJAAAAWEIiCQAAPB57JK2hkQQAAB6PPtIalrYBAADcRHx8vG655RZVrlxZISEhuvvuu3XgwAGHOQMHDpTNZnN4tGzZ0mFObm6uhg8fruDgYPn7+6tHjx46duyYw5zMzEzFxsbKbrfLbrcrNjZWZ86cKVW9NJIAAMDj/b4xu5KP0ti8ebOGDRumpKQkrV+/XhcuXFDHjh117tw5h3mdO3dWWlqa+Vi7dq3D8ZEjR2r16tVasWKFtmzZouzsbHXr1k0FBQXmnH79+ik1NVWJiYlKTExUamqqYmNjS1UvS9sAAABuIjEx0eHnRYsWKSQkRCkpKbrjjjvMcT8/P4WFhRV7jqysLC1cuFBLly5V+/btJUlvvfWWqlevrs8++0ydOnXS/v37lZiYqKSkJEVFRUmSFixYoOjoaB04cEANGjQoUb0kkgAAwOPZbM575Obm6uzZsw6P3NzcEtWVlZUlSQoMDHQY37Rpk0JCQlS/fn0NHjxYGRkZ5rGUlBTl5+erY8eO5lhERIQiIyO1detWSdK2bdtkt9vNJlKSWrZsKbvdbs4pCRpJAAAAJ4qPjzf3IV56xMfH/+nzDMPQqFGjdNtttykyMtIc79Kli5YtW6YNGzbopZdeUnJystq2bWs2p+np6fL19VWVKlUczhcaGqr09HRzTkhISJHXDAkJMeeUBEvbAADA45Vz4mXb48eP16hRoxzG/Pz8/vR5TzzxhL755htt2bLFYbx3797mnyMjI9WiRQvVqFFDH3/8sXr27HnZ8xmG4bBns7j9m7+f82doJAEAAJzIz8+vRI3jbw0fPlwffvihvvjiC11//fV/ODc8PFw1atTQ999/L0kKCwtTXl6eMjMzHVLJjIwMxcTEmHOOHz9e5FwnTpxQaGhoietkaRsAAHg8Z+6RLA3DMPTEE09o1apV2rBhg2rVqvWnzzl16pR++uknhYeHS5KaN28uHx8frV+/3pyTlpamPXv2mI1kdHS0srKytGPHDnPO9u3blZWVZc4pCRJJAADg8dzlm22GDRum5cuX64MPPlDlypXN/Yp2u10VKlRQdna24uLidO+99yo8PFxHjhzR008/reDgYN1zzz3m3EGDBmn06NEKCgpSYGCgxowZo8aNG5tXcTds2FCdO3fW4MGDNX/+fEnSkCFD1K1btxJfsS3RSAIAALiNefPmSZJat27tML5o0SINHDhQXl5e2r17t5YsWaIzZ84oPDxcbdq00cqVK1W5cmVz/qxZs+Tt7a1evXopJydH7dq1U0JCgry8vMw5y5Yt04gRI8yru3v06KG5c+eWql6bYRiGxffqtio0fcLVJQBwkszk0v1LDsC1o7wL460u87Y77dyfPB7155OuUeyRBAAAgCUsbQMAAI/nLnskrzUkkgAAALCERBIAAHg8AklrSCQBAABgCYkkAADweDYRSVpBIwkAADxeOfpIS1jaBgAAgCUkkgAAwONx+x9rSCQBAABgCYkkAADweASS1pBIAgAAwBISSQAA4PHKEUlaQiIJAAAAS0gkAQCAxyOQtIZGEgAAeDxu/2MNS9sAAACwhEQSAAB4PAJJa0gkAQAAYAmJJAAA8Hjc/scaEkkAAABYQiIJAAA8HnmkNSSSAAAAsIREEgAAeDzuI2kNjSQAAPB45egjLWFpGwAAAJaQSAIAAI/H0rY1JJIAAACwhEQSAAB4PAJJa0gkAQAAYAmJJAAA8HjskbSGRBIAAACWkEgCAACPx30kraGRBAAAHo+lbWtY2gYAAIAlJJIAAMDjkUdaQyIJAAAASyw1kkuXLtXf//53RURE6Mcff5QkzZ49Wx988MEVLQ4AAOBqKGezOe1RlpW6kZw3b55GjRqlO++8U2fOnFFBQYEk6brrrtPs2bOvdH0AAABwU6VuJF9++WUtWLBAEyZMkJeXlzneokUL7d69+4oWBwAAcDXYbM57lGWlbiQPHz6spk2bFhn38/PTuXPnrkhRAAAAcH+lbiRr1aql1NTUIuOffPKJGjVqdCVqAgAAuKpsNpvTHmVZqW//89RTT2nYsGH69ddfZRiGduzYobffflvx8fF64403nFEjAAAA3FCpG8mHHnpIFy5c0NixY3X+/Hn169dP1apV05w5c9SnTx9n1AgAAOBUZTw4dBpLNyQfPHiwBg8erJMnT6qwsFAhISFXui4AAICrpqzfpsdZ/tI32wQHB1+pOgAAAHCNKXUjWatWrT/cOPrDDz/8pYIAAACuNgJJa0p91fbIkSP15JNPmo+hQ4cqOjpaWVlZGjJkiDNqBAAA8Ajx8fG65ZZbVLlyZYWEhOjuu+/WgQMHHOYYhqG4uDhFRESoQoUKat26tfbu3eswJzc3V8OHD1dwcLD8/f3Vo0cPHTt2zGFOZmamYmNjZbfbZbfbFRsbqzNnzpSq3lInkk8++WSx46+88op27txZ2tMBAAC4nLvcpmfz5s0aNmyYbrnlFl24cEETJkxQx44dtW/fPvn7+0uSZsyYoZkzZyohIUH169fXlClT1KFDBx04cECVK1eWdDH4W7NmjVasWKGgoCCNHj1a3bp1U0pKivmFMv369dOxY8eUmJgoSRoyZIhiY2O1Zs2aEtdrMwzDuBJv/IcfflCTJk109uzZK3G6v6RC0ydcXQIAJ8lMnuvqEgA4Sfm/dOXGXzNs9X6nnXvmnbWVm5vrMObn5yc/P78/fe6JEycUEhKizZs364477pBhGIqIiNDIkSM1btw4SRfTx9DQUE2fPl2PPvqosrKyVLVqVS1dulS9e/eWJP3888+qXr261q5dq06dOmn//v1q1KiRkpKSFBUVJUlKSkpSdHS0vv32WzVo0KBE7+2K/U/27rvvKjAw8Eqd7i/hLxqg7KrSNs7FFQBwlpwv4lz22qXe61cK8fHxmjx5ssPYpEmTFBcX96fPzcrKkiSzxzp8+LDS09PVsWNHc46fn59atWqlrVu36tFHH1VKSory8/Md5kRERCgyMlJbt25Vp06dtG3bNtntdrOJlKSWLVvKbrdr69atzmskmzZt6hD/Goah9PR0nThxQq+++mppTwcAAFCmjR8/XqNGjXIYK0kaaRiGRo0apdtuu02RkZGSpPT0dElSaGiow9zQ0FD9+OOP5hxfX19VqVKlyJxLz09PTy/29o0hISHmnJIodSN59913O/xcrlw5Va1aVa1bt9bf/va30p4OAADA5Zy5R7Kky9i/98QTT+ibb77Rli1bihz7fb2GYfzpe/j9nOLml+Q8v1WqRvLChQuqWbOmOnXqpLCwsNI8FQAAwG2Vc49rbUzDhw/Xhx9+qC+++ELXX3+9OX6p/0pPT1d4eLg5npGRYaaUYWFhysvLU2ZmpkMqmZGRoZiYGHPO8ePHi7zuiRMniqSdf6RUWwK8vb31+OOPF9kwCgAAgL/OMAw98cQTWrVqlTZs2KBatWo5HK9Vq5bCwsK0fv16cywvL0+bN282m8TmzZvLx8fHYU5aWpr27Nljzrl068YdO3aYc7Zv366srCxzTkmUemk7KipKu3btUo0aNUr7VAAAALfkLonksGHDtHz5cn3wwQeqXLmyuV/RbrerQoUKstlsGjlypKZOnap69eqpXr16mjp1qipWrKh+/fqZcwcNGqTRo0crKChIgYGBGjNmjBo3bqz27dtLkho2bKjOnTtr8ODBmj9/vqSLt//p1q1biS+0kSw0kkOHDtXo0aN17NgxNW/e3Lyn0SU33XRTaU8JAAAASfPmzZMktW7d2mF80aJFGjhwoCRp7NixysnJ0dChQ5WZmamoqCitW7fOvIekJM2aNUve3t7q1auXcnJy1K5dOyUkJJj3kJSkZcuWacSIEebV3T169NDcuaW7802J7yP58MMPa/bs2bruuuuKnsRmMzdnFhQUlKoAZ/j1gqsrAOAsVdrGubgCAM7iytv/jF5z4M8nWfRS95InfNeaEieSixcv1rRp03T48GFn1gMAAIBrRIkbyUvBJXsjAQBAWeMueySvNaW6attdvocSAAAArleqi23q16//p83k6dOn/1JBAAAAVxtZmTWlaiQnT54su93urFoAAABcohydpCWlaiT79OlT7PcyAgAAwPOUuJFkfyQAACirSnXRCEwl/txKeLtJAAAAeIgSJ5KFhYXOrAMAAMBlWHi1hiQXAAAAlpT6u7YBAADKGq7atoZEEgAAAJaQSAIAAI9HIGkNjSQAAPB4fNe2NSxtAwAAwBISSQAA4PG42MYaEkkAAABYQiIJAAA8HoGkNSSSAAAAsIREEgAAeDyu2raGRBIAAACWkEgCAACPZxORpBU0kgAAwOOxtG0NS9sAAACwhEQSAAB4PBJJa0gkAQAAYAmJJAAA8Hg27khuCYkkAAAALCGRBAAAHo89ktaQSAIAAMASEkkAAODx2CJpDY0kAADweOXoJC1haRsAAACWkEgCAACPx8U21pBIAgAAwBISSQAA4PHYImkNiSQAAAAsIZEEAAAer5yIJK0gkQQAAIAlJJIAAMDjsUfSGhpJAADg8bj9jzUsbQMAAMASEkkAAODx+IpEa0gkAQAAYAmJJAAA8HgEktaQSAIAAMASGkkAAODxytlsTnuU1hdffKHu3bsrIiJCNptN77//vsPxgQMHymazOTxatmzpMCc3N1fDhw9XcHCw/P391aNHDx07dsxhTmZmpmJjY2W322W32xUbG6szZ86U7nMr9bsDAACA05w7d04333yz5s6de9k5nTt3VlpamvlYu3atw/GRI0dq9erVWrFihbZs2aLs7Gx169ZNBQUF5px+/fopNTVViYmJSkxMVGpqqmJjY0tVK3skAQCAx3OnPZJdunRRly5d/nCOn5+fwsLCij2WlZWlhQsXaunSpWrfvr0k6a233lL16tX12WefqVOnTtq/f78SExOVlJSkqKgoSdKCBQsUHR2tAwcOqEGDBiWqlUQSAAB4vHJOfOTm5urs2bMOj9zc3L9U76ZNmxQSEqL69etr8ODBysjIMI+lpKQoPz9fHTt2NMciIiIUGRmprVu3SpK2bdsmu91uNpGS1LJlS9ntdnNOSdBIAgAAOFF8fLy5D/HSIz4+3vL5unTpomXLlmnDhg166aWXlJycrLZt25rNaXp6unx9fVWlShWH54WGhio9Pd2cExISUuTcISEh5pySYGkbAAB4PJsT17bHjx+vUaNGOYz5+flZPl/v3r3NP0dGRqpFixaqUaOGPv74Y/Xs2fOyzzMMw+F9Fveefz/nz9BIAgAAOJGfn99fahz/THh4uGrUqKHvv/9ekhQWFqa8vDxlZmY6pJIZGRmKiYkx5xw/frzIuU6cOKHQ0NASvzZL2wAAwOPZnPhwtlOnTumnn35SeHi4JKl58+by8fHR+vXrzTlpaWnas2eP2UhGR0crKytLO3bsMOds375dWVlZ5pySIJEEAABwI9nZ2Tp48KD58+HDh5WamqrAwEAFBgYqLi5O9957r8LDw3XkyBE9/fTTCg4O1j333CNJstvtGjRokEaPHq2goCAFBgZqzJgxaty4sXkVd8OGDdW5c2cNHjxY8+fPlyQNGTJE3bp1K/EV2xKNJAAAgKUbhzvLzp071aZNG/PnS/srBwwYoHnz5mn37t1asmSJzpw5o/DwcLVp00YrV65U5cqVzefMmjVL3t7e6tWrl3JyctSuXTslJCTIy8vLnLNs2TKNGDHCvLq7R48ef3jvyuLYDMMw/sqbdUe/XnB1BQCcpUrbOBdXAMBZcr6Ic9lrv5Vy7M8nWfRA8+uddm5XI5EEAAAez33yyGsLjSQAAPB4brSyfU3hqm0AAABYQiIJAAA8njNvSF6WkUgCAADAEhJJAADg8UjWrOFzAwAAgCUkkgAAwOOxR9IaEkkAAABYQiIJAAA8HnmkNSSSAAAAsIREEgAAeDz2SFpDIwkAADweS7TW8LkBAADAEhJJAADg8VjatoZEEgAAAJaQSAIAAI9HHmkNiSQAAAAsIZEEAAAejy2S1pBIAgAAwBISSQAA4PHKsUvSEhpJAADg8VjatoalbQAAAFhCIgkAADyejaVtS0gkAQAAYIlbNJJHjx6VYRhFxg3D0NGjR11QEQAA8CQ2m/MeZZlbNJK1atXSiRMnioyfPn1atWrVckFFAAAA+DNusUfSMIxivyw9Oztb5cuXd0FFAADAk3D7H2tc2kiOGjVKkmSz2TRx4kRVrFjRPFZQUKDt27erSZMmLqoOAAAAf8SljeSuXbskXUwkd+/eLV9fX/OYr6+vbr75Zo0ZM8ZV5QEAAA9R1vcyOotLG8mNGzdKkh566CHNmTNHAQEBriwHAAB4KBpJa9xij+SiRYtcXQIAAABKyS0ayXPnzmnatGn6/PPPlZGRocLCQofjP/zwg4sqAwAAnoAbklvjFo3kI488os2bNys2Nlbh4eHFXsENAAAA9+IWjeQnn3yijz/+WH//+99dXQoAAPBA5ciwLHGLG5JXqVJFgYGBri4DAAAApeAWjeTzzz+vZ599VufPn3d1KQAAwAPZnPhPWeYWS9svvfSSDh06pNDQUNWsWVM+Pj4Ox7/66isXVQYAAIDLcYtG8u6773Z1CQAAwINxna81btFITpo0ydUlAAAAD1bWl6CdxS32SAIAAODa4xaJZEFBgWbNmqV33nlHR48eVV5ensPx06dPu6gyAADgCbj9jzVukUhOnjxZM2fOVK9evZSVlaVRo0apZ8+eKleunOLi4lxdHgAAAIrhFo3ksmXLtGDBAo0ZM0be3t7q27ev3njjDT377LNKSkpydXkAAKCM4/Y/1rhFI5menq7GjRtLkipVqqSsrCxJUrdu3fTxxx+7sjQAAABchlvskbz++uuVlpamG264QXXr1tW6devUrFkzJScny8/Pz9XlwY2tfHuZEhYt1MkTJ1Snbj2N/efTata8havLAvB/Bt/VQoPvvkU1wq6TJO0/nKGpizdr3faDkiT/Cr6a8mh7db/tbwq0V9CP6Wf06rvbteCDneY5fH28NG1oR93frrEq+Hlr41eHNXLmx/qfE2fNOWNjb1eX6Pq6qW6Y8vILFN512lV9n7j2cfsfa9wikbznnnv0+eefS5KefPJJTZw4UfXq1dODDz6ohx9+2MXVwV0lfrJWM6bFa/CQx7Xy3ffVrFlzDX10sNJ+/tnVpQH4P/9z4qwmzv9Mfx/8uv4++HVt+uqw/jO1rxrWrCpJmvFEJ3W4ta4emrJKTWJf0cvvJGnmk3eq220NzHO8OLyzetzeUA9OflftnnhTlSr46r1p/VTuN1dH+Hp7adXGvVrwQfJVf4+AJ3OLRnLatGl6+umnJUn33XeftmzZoscff1z/+c9/NG0a/1WJ4i1dvEj33Huvet53v2rXqaOx4ycoLDxM76x829WlAfg/a7d+p0+TvtfBY6d08Ngpxb2xQdk5ebr1xuslSVE3Vtdbian6b+oRHU0/ozfXpOibQ+lq1iBCkhTg76eBXZvpn69+qo0pP+jr79P18POrFFk7RG2b1zZfZ8qiTXr5P0nacyjDJe8T1z6bEx+l9cUXX6h79+6KiIiQzWbT+++/73DcMAzFxcUpIiJCFSpUUOvWrbV3716HObm5uRo+fLiCg4Pl7++vHj166NixYw5zMjMzFRsbK7vdLrvdrtjYWJ05c6ZUtbpFI/n779iOiorSqFGj1KNHDxdVBHeXn5en/fv2KjrmNofx6Ji/6+vUXS6qCsAfKVfOpvvbRsq/vI+277n4F9rW3UfV7e8NFBFcWZJ0R9Oaqlc9SJ/tOCRJatogQr4+XubPkpR26hftPZyhlpHVr/6bQJlVzmZz2qO0zp07p5tvvllz584t9viMGTM0c+ZMzZ07V8nJyQoLC1OHDh30yy+/mHNGjhyp1atXa8WKFdqyZYuys7PVrVs3FRQUmHP69eun1NRUJSYmKjExUampqYqNjS1VrW6xRzIkJER33323YmNj1aFDB5UrV/L+Njc3V7m5uQ5jhpcfeyvLuMwzmSooKFBQUJDDeFBQsE6ePOGiqgAU58baIdr06iMq7+ut7Jw89X5mpb798eLv6eg5n+jVsd11aNVo5V8oUGGhocdnfKitu49KksICKyk374LOZP/qcM6MzHMKDap01d8LcDV06dJFXbp0KfaYYRiaPXu2JkyYoJ49e0qSFi9erNDQUC1fvlyPPvqosrKytHDhQi1dulTt27eXJL311luqXr26PvvsM3Xq1En79+9XYmKikpKSFBUVJUlasGCBoqOjdeDAATVo0KDY1/89t0gklyxZotzcXN1zzz2KiIjQk08+qeTkku1ziY+PNyPZS48Xp8c7uWK4C9vv/kvPMIwiYwBc67ujpxQ16DW1evwNLfggWQuevlt/q3Fxj+Sw+6J0a6Prde8/lyvmkdf1z1fXac6ormrzm2Xr4tgkGcZVKB4ew5lL27m5uTp79qzD4/chWEkdPnxY6enp6tixoznm5+enVq1aaevWrZKklJQU5efnO8yJiIhQZGSkOWfbtm2y2+1mEylJLVu2lN1uN+eUhFs0kj179tR//vMfHT9+XPHx8dq/f79iYmJUv359Pffcc3/43PHjxysrK8vh8dS48VepcrhKleuqyMvLSydPnnQYP336lIKCgl1UFYDi5F8o0A//c1pfHfhZz77+uXYfPK5h90epvK+3Jg9up3FzP9Xard9pzw/H9dqqHXp3w16N7BMjSUo/nS0/X29dV6m8wzmrVvFXxulsV7wdoNSKC73i462FXunp6ZKk0NBQh/HQ0FDzWHp6unx9fVWlSpU/nBMSElLk/CEhIeacknCLRvKSypUr66GHHtK6dev09ddfy9/fX5MnT/7D5/j5+SkgIMDhwbJ22efj66uGjW5U0tYvHcaTtm7VzU2auqgqACVhs0l+Pt7y8faSr4+XCn8XLRYUFppXZO868LPy8gvU7pY65vGwoEq6sVaIkvb8dFXrRhnnxEiyuNBr/Pi/FnpZWZH7/Zzi5pd2Zc8t9khe8uuvv+rDDz/U8uXLlZiYqJCQEI0ZM8bVZcFNxQ54SBP+OVaNIiN1881N9d5/ViotLU339+7j6tIA/J/Jg9tp3fbv9VPGWVWu6Kv720bqjiY11eOpt/TL+Vx9seuIpj7eUTm5F3T0+BndfnNN9e90s8bN/VSSdPZcrhI+/krThnXUqazzyvwlR/FDO2rPDxnakPKD+TrVQ+yqElBB1UPt8vKy6aa6YZKkQ/9zWudy8lzy3oFL/Pyu3LUbYWEX/7+dnp6u8PBwczwjI8NMKcPCwpSXl6fMzEyHVDIjI0MxMTHmnOPHjxc5/4kTJ4qknX/ELRrJdevWadmyZXr//ffl5eWl++67T59++qlatWrl6tLgxjp3uVNZZzL1+rxXdeJEhurWq69XXntdERHVXF0agP8TEuivhRN6KiyokrLO5WrPoePq8dRb2rDzYhP44OR39dyQdkqY2FNVAiroaHqW4hZscLgh+di5n6qgoFBvTb5fFfx8tDHlBw2JX67Cwv9PMicOaqPYLk3Mn7e/+ZgkqeOIBP039chVea+4tl0rX2VYq1YthYWFaf369Wra9OIKXF5enjZv3qzp06dLkpo3by4fHx+tX79evXr1kiSlpaVpz549mjFjhiQpOjpaWVlZ2rFjh2699VZJ0vbt25WVlWU2myVhMwzXb1euWLGiunbtqv79+6tr167y8fH5S+f79cIVKgyA26nSNs7FFQBwlpwv4lz22tsPZTnt3FF17KWan52drYMHL377U9OmTTVz5ky1adNGgYGBuuGGGzR9+nTFx8dr0aJFqlevnqZOnapNmzbpwIEDqlz54q20Hn/8cX300UdKSEhQYGCgxowZo1OnTiklJUVeXl6SLl4d/vPPP2v+/PmSpCFDhqhGjRpas2ZNiWt1i0QyPT1dAQEBri4DAAB4KHe64cfOnTvVpk0b8+dRo0ZJkgYMGKCEhASNHTtWOTk5Gjp0qDIzMxUVFaV169aZTaQkzZo1S97e3urVq5dycnLUrl07JSQkmE2kJC1btkwjRowwr+7u0aPHZe9deTlukUhK0qFDh7Ro0SIdOnRIc+bMUUhIiBITE1W9enXdeOONpToXiSRQdlVpG+fiCgA4iysTyeQfnJdI3lK7dInktcQtrtrevHmzGjdurO3bt2vVqlXKzr54S4dvvvlGkyZNcnF1AAAAKI5bNJL//Oc/NWXKFK1fv16+vr7meJs2bbRt2zYXVgYAADyCO33Z9jXELRrJ3bt365577ikyXrVqVZ06dcoFFQEAAODPuEUjed111yktLa3I+K5du1StGrdyAQAAzmVz4j9lmVs0kv369dO4ceOUnp4um82mwsJCffnllxozZowefPBBV5cHAACAYrhFI/nCCy/ohhtuULVq1ZSdna1GjRrpjjvuUExMjJ555hlXlwcAAMo4m815j7LMLe4j6ePjo2XLlum5557Trl27VFhYqKZNm6pevXquLg0AAACX4RaN5CV16tRRnTp1XF0GAADwMGU8OHQalzWSl+7SXhIzZ850YiUAAMDj0Ula4rJGcteuXSWaZyvrmwsAAACuUS5rJDdu3OiqlwYAAHBQ1m/T4yxucdX2JQcPHtSnn36qnJwcSZKbfA04AAAAiuEWjeSpU6fUrl071a9fX3feead5c/JHHnlEo0ePdnF1AACgrOP2P9a4RSP5j3/8Qz4+Pjp69KgqVqxojvfu3VuJiYkurAwAAACX4xa3/1m3bp0+/fRTXX/99Q7j9erV048//uiiqgAAgKco48Gh07hFInnu3DmHJPKSkydPys/PzwUVAQAA4M+4RSN5xx13aMmSJebPl75v+8UXX1SbNm1cWBkAAPAINic+yjC3WNr+17/+pVatWmnnzp3Ky8vT2LFjtXfvXp0+fVpffvmlq8sDAABlHLf/scbliWR+fr6GDh2qDz/8ULfeeqs6dOigc+fOqWfPntq1axdfmQgAAOCmXJ5I+vj4aM+ePQoKCtLkyZNdXQ4AAPBAZf02Pc7i8kRSkh588EEtXLjQ1WUAAACgFFyeSEpSXl6e3njjDa1fv14tWrSQv7+/w/GZM2e6qDIAAOAJCCStcYtGcs+ePWrWrJkk6bvvvnM4ZiNrBgAAcEtu0Uhu3LjR1SUAAABPRm5liVvskQQAAMC1xy0SSQAAAFfiPpLWkEgCAADAEhJJAADg8bi21xoaSQAA4PHoI61haRsAAACWkEgCAAAQSVpCIgkAAABLSCQBAIDH4/Y/1pBIAgAAwBISSQAA4PG4/Y81JJIAAACwhEQSAAB4PAJJa2gkAQAA6CQtYWkbAAAAlpBIAgAAj8ftf6whkQQAAIAlJJIAAMDjcfsfa0gkAQAAYAmJJAAA8HgEktaQSAIAAMASEkkAAAAiSUtIJAEAgMezOfGf0oiLi5PNZnN4hIWFmccNw1BcXJwiIiJUoUIFtW7dWnv37nU4R25uroYPH67g4GD5+/urR48eOnbs2BX5nH6PRhIAAMCN3HjjjUpLSzMfu3fvNo/NmDFDM2fO1Ny5c5WcnKywsDB16NBBv/zyizln5MiRWr16tVasWKEtW7YoOztb3bp1U0FBwRWvlaVtAADg8dzp9j/e3t4OKeQlhmFo9uzZmjBhgnr27ClJWrx4sUJDQ7V8+XI9+uijysrK0sKFC7V06VK1b99ekvTWW2+pevXq+uyzz9SpU6crWiuJJAAAgBPl5ubq7NmzDo/c3NzLzv/+++8VERGhWrVqqU+fPvrhhx8kSYcPH1Z6ero6duxozvXz81OrVq20detWSVJKSory8/Md5kRERCgyMtKccyXRSAIAAI9nc+IjPj5edrvd4REfH19sHVFRUVqyZIk+/fRTLViwQOnp6YqJidGpU6eUnp4uSQoNDXV4TmhoqHksPT1dvr6+qlKlymXnXEksbQMAADjR+PHjNWrUKIcxPz+/Yud26dLF/HPjxo0VHR2tOnXqaPHixWrZsqUkyfa7dXjDMIqM/V5J5lhBIgkAAODESNLPz08BAQEOj8s1kr/n7++vxo0b6/vvvzf3Tf4+WczIyDBTyrCwMOXl5SkzM/Oyc64kGkkAAAA3lZubq/379ys8PFy1atVSWFiY1q9fbx7Py8vT5s2bFRMTI0lq3ry5fHx8HOakpaVpz5495pwriaVtAADg8Up7v0dnGTNmjLp3764bbrhBGRkZmjJlis6ePasBAwbIZrNp5MiRmjp1qurVq6d69epp6tSpqlixovr16ydJstvtGjRokEaPHq2goCAFBgZqzJgxaty4sXkV95VEIwkAADyeu9z+59ixY+rbt69OnjypqlWrqmXLlkpKSlKNGjUkSWPHjlVOTo6GDh2qzMxMRUVFad26dapcubJ5jlmzZsnb21u9evVSTk6O2rVrp4SEBHl5eV3xem2GYRhX/Kwu9usFV1cAwFmqtI1zcQUAnCXniziXvfbR05e/Hc9fdUNgyfZDXotIJAEAgMdzk0DymsPFNgAAALCERBIAAHg8d9kjea0hkQQAAIAlJJIAAADskrSERBIAAACWkEgCAACPxx5Ja2gkAQCAx6OPtIalbQAAAFhCIgkAADweS9vWkEgCAADAEhJJAADg8WzskrSERBIAAACWkEgCAAAQSFpCIgkAAABLSCQBAIDHI5C0hkYSAAB4PG7/Yw1L2wAAALCERBIAAHg8bv9jDYkkAAAALCGRBAAAIJC0hEQSAAAAlpBIAgAAj0cgaQ2JJAAAACwhkQQAAB6P+0haQyMJAAA8Hrf/sYalbQAAAFhCIgkAADweS9vWkEgCAADAEhpJAAAAWEIjCQAAAEvYIwkAADweeyStIZEEAACAJSSSAADA43EfSWtoJAEAgMdjadsalrYBAABgCYkkAADweASS1pBIAgAAwBISSQAAACJJS0gkAQAAYAmJJAAA8Hjc/scaEkkAAABYQiIJAAA8HveRtIZEEgAAAJaQSAIAAI9HIGkNjSQAAACdpCUsbQMAAMASGkkAAODxbE78x4pXX31VtWrVUvny5dW8eXP997//vcLv+MqgkQQAAHAjK1eu1MiRIzVhwgTt2rVLt99+u7p06aKjR4+6urQibIZhGK4u4kr79YKrKwDgLFXaxrm4AgDOkvNFnMte25m9Q/lSXpESFRWlZs2aad68eeZYw4YNdffddys+Pv4KV/fXkEgCAAA4UW5urs6ePevwyM3NLXZuXl6eUlJS1LFjR4fxjh07auvWrVej3FIpk1dtl7bzx7UrNzdX8fHxGj9+vPz8/FxdDq4CVyYWuLr4/cbV5MzeIW5KvCZPnuwwNmnSJMXFxRWZe/LkSRUUFCg0NNRhPDQ0VOnp6c4r0qIyubQNz3H27FnZ7XZlZWUpICDA1eUAuIL4/UZZkZubWySB9PPzK/Y/kH7++WdVq1ZNW7duVXR0tDn+wgsvaOnSpfr222+dXm9pkN0BAAA40eWaxuIEBwfLy8urSPqYkZFRJKV0B+yRBAAAcBO+vr5q3ry51q9f7zC+fv16xcTEuKiqyyORBAAAcCOjRo1SbGysWrRooejoaL3++us6evSoHnvsMVeXVgSNJK5pfn5+mjRpEhvxgTKI3294qt69e+vUqVN67rnnlJaWpsjISK1du1Y1atRwdWlFcLENAAAALGGPJAAAACyhkQQAAIAlNJIAAACwhEYSf1nr1q01cuTIK37ehIQEXXfddVf8vACuPmf9ewKAa9FI4i9btWqVnn/+eVeXcdXQ4AJlBw0u8NfQSOIvCwwMVOXKlYs9lpeXV2SsoKBAhYWFzi4LwFVS3O85AM9AI4m/7Lf/RV+zZk1NmTJFAwcOlN1u1+DBg80E76OPPlKjRo3k5+enH3/8UXl5eRo7dqyqVasmf39/RUVFadOmTX/4WmvWrFHz5s1Vvnx51a5dW5MnT9aFCxckSX379lWfPn0c5ufn5ys4OFiLFi2SJCUmJuq2227Tddddp6CgIHXr1k2HDh0y5x85ckQ2m02rVq1SmzZtVLFiRd18883atm2bJGnTpk166KGHlJWVJZvNJpvNpri4uCvzQQLXiNatW+uJJ57QqFGjFBwcrA4dOmjfvn268847ValSJYWGhio2NlYnT5687Dn+6Pc/KytLFSpUUGJiosNzVq1aJX9/f2VnZ0uSxo0bp/r166tixYqqXbu2Jk6cqPz8fHN+XFycmjRpoqVLl6pmzZqy2+3q06ePfvnlF0nSwIEDtXnzZs2ZM8f8fT5y5MiV/bCAMo5GElfciy++qMjISKWkpGjixImSpPPnzys+Pl5vvPGG9u7dq5CQED300EP68ssvtWLFCn3zzTe6//771blzZ33//ffFnvfTTz/VAw88oBEjRmjfvn2aP3++EhIS9MILL0iS+vfvrw8//ND8S+bSc86dO6d7771XknTu3DmNGjVKycnJ+vzzz1WuXDndc889RRLSCRMmaMyYMUpNTVX9+vXVt29fXbhwQTExMZo9e7YCAgKUlpamtLQ0jRkzxhkfI+DWFi9eLG9vb3355ZeaNm2aWrVqpSZNmmjnzp1KTEzU8ePH1atXr8s+/49+/+12u7p27aply5Y5PGf58uW66667VKlSJUlS5cqVlZCQoH379mnOnDlasGCBZs2a5fCcQ4cO6f3339dHH32kjz76SJs3b9a0adMkSXPmzFF0dLQGDx5s/j5Xr179Cn9SQBlnAH9Rq1atjCeffNIwDMOoUaOGcffddzscX7RokSHJSE1NNccOHjxo2Gw243/+538c5rZr184YP368+Ty73W4eu/32242pU6c6zF+6dKkRHh5uGIZh5OXlGcHBwcaSJUvM43379jXuv//+y9aekZFhSDJ2795tGIZhHD582JBkvPHGG+acvXv3GpKM/fv3F1sX4GlatWplNGnSxPx54sSJRseOHR3m/PTTT4Yk48CBA+ZzLv17oiS//6tWrTIqVapknDt3zjAMw8jKyjLKly9vfPzxx5eta8aMGUbz5s3NnydNmmRUrFjROHv2rDn21FNPGVFRUQ7v5VJdAEqPr0jEFdeiRYsiY76+vrrpppvMn7/66isZhqH69es7zMvNzVVQUFCx501JSVFycrKZQEoX91v++uuvOn/+vCpWrKj7779fy5YtU2xsrM6dO6cPPvhAy5cvN+cfOnRIEydOVFJSkk6ePGkmkUePHlVkZKQ577e1hoeHS5IyMjL0t7/9rTQfBVBm/fb3PCUlRRs3bjSTwt86dOhQkd/zkvz+d+3aVd7e3vrwww/Vp08fvffee6pcubI6duxozn/33Xc1e/ZsHTx4UNnZ2bpw4YICAgIczlmzZk2HPdzh4eHKyMiw/sYBOKCRxBXn7+9fZKxChQqy2Wzmz4WFhfLy8lJKSoq8vLwc5hb3l9Gl50yePFk9e/Yscqx8+fKSLi5vt2rVShkZGVq/fr3Kly+vLl26mPO6d++u6tWra8GCBYqIiFBhYaEiIyOLXCzg4+Nj/vlS3VwgBPy/3/6eFxYWqnv37po+fXqReZf+Q+y3SvL77+vrq/vuu0/Lly9Xnz59tHz5cvXu3Vve3hf/2kpKSlKfPn00efJkderUSXa7XStWrNBLL73kcL7f/i5LF3+f+V0GrhwaSbhE06ZNVVBQoIyMDN1+++0lek6zZs104MAB1a1b97JzYmJiVL16da1cuVKffPKJ7r//fvn6+kqSTp06pf3792v+/Pnma27ZsqXUtfv6+qqgoKDUzwPKqmbNmum9995TzZo1zUbvj5T0979///7q2LGj9u7dq40bNzrcZuzLL79UjRo1NGHCBHPsxx9/LHXt/D4Dfw0X28Al6tevr/79++vBBx/UqlWrdPjwYSUnJ2v69Olau3Ztsc959tlntWTJEsXFxWnv3r3av3+/Vq5cqWeeecacY7PZ1K9fP7322mtav369HnjgAfNYlSpVFBQUpNdff10HDx7Uhg0bNGrUqFLXXrNmTWVnZ+vzzz/XyZMndf78+dJ/AEAZMmzYMJ0+fVp9+/bVjh079MMPP2jdunV6+OGHi23SSvr736pVK4WGhqp///6qWbOmWrZsaR6rW7eujh49qhUrVujQoUP697//rdWrV5e69po1a2r79u06cuSIw3YXACVDIwmXWbRokR588EGNHj1aDRo0UI8ePbR9+/bLXjXZqVMnffTRR1q/fr1uueUWtWzZUjNnzlSNGjUc5vXv31/79u1TtWrV9Pe//90cL1eunFasWKGUlBRFRkbqH//4h1588cVS1x0TE6PHHntMvXv3VtWqVTVjxoxSnwMoSyIiIvTll1+qoKBAnTp1UmRkpJ588knZ7XaVK1f8XzMl+f232Wzq27evvv76a/Xv39/h+XfddZf+8Y9/6IknnlCTJk20detW8y4RpTFmzBh5eXmpUaNGqlq1qo4ePVrqcwCezGYYhuHqIgAAAHDtIZEEAACAJTSSAAAAsIRGEgAAAJbQSAIAAMASGkkAAABYQiMJAAAAS2gkAQAAYAmNJAAAACyhkQTgtuLi4tSkSRPz54EDB+ruu+++6nUcOXJENptNqampV/21AcCd0UgCKLWBAwfKZrPJZrPJx8dHtWvX1pgxY3Tu3Dmnvu6cOXOUkJBQork0fwDgfN6uLgDAtalz585atGiR8vPz9d///lePPPKIzp07p3nz5jnMy8/Pl4+PzxV5TbvdfkXOAwC4MkgkAVji5+ensLAwVa9eXf369VP//v31/vvvm8vRb775pmrXri0/Pz8ZhqGsrCwNGTJEISEhCggIUNu2bfX11187nHPatGkKDQ1V5cqVNWjQIP36668Ox3+/tF1YWKjp06erbt268vPz0w033KAXXnhBklSrVi1JUtOmTWWz2dS6dWvzeYsWLVLDhg1Vvnx5/e1vf9Orr77q8Do7duxQ06ZNVb58ebVo0UK7du26gp8cAJQdJJIArogKFSooPz9fknTw4EG98847eu+99+Tl5SVJ6tq1qwIDA7V27VrZ7XbNnz9f7dq103fffafAwEC98847mjRpkl555RXdfvvtWrp0qf7973+rdu3al33N8ePHa8GCBZo1a5Zuu+02paWl6dtvv5V0sRm89dZb9dlnn+nGG2+Ur6+vJGnBggWaNGmS5s6dq6ZNm2rXrl0aPHiw/P39NWDAAJ07d07dunVT27Zt9dZbb+nw4cN68sknnfzpAcA1ygCAUhowYIBx1113mT9v377dCAoKMnr16mVMmjTJ8PHxMTIyMszjn3/+uREQEGD8+uuvDuepU6eOMX/+fMMwDCM6Otp47LHHHI5HRUUZN998c7Gve/bsWcPPz89YsGBBsTUePnzYkGTs2rXLYbx69erG8uXLHcaef/55Izo62jAMw5g/f74RGBhonDt3zjw+b968Ys8FAJ6OpW0Alnz00UeqVKmSypcvr+joaN1xxx16+eWXJUk1atRQ1apVzbkpKSnKzs5WUFCQKlWqZD4OHz6sQ4cOSZL279+v6Ohoh9f4/c+/tX//fuXm5qpdu3YlrvnEiRP66aefNGjQIIc6pkyZ4lDHzTffrIoVK5aoDgDwZCxtA7CkTZs2mjdvnnx8fBQREeFwQY2/v7/D3MLCQoWHh2vTpk1FznPddddZev0KFSqU+jmFhYWSLi5vR0VFORy7tARvGIalegDAE9FIArDE399fdevWLdHcZs2aKT09Xd7e3qpZs2axcxo2bKikpCQ9+OCD5lhSUtJlz1mvXj1VqFBBn3/+uR555JEixy/tiSwoKDDHQkNDVa1aNf3www/q379/sedt1KiRli5dqpycHLNZ/aM6AMCTsbQNwOnat2+v6Oho3X333fr000915MgRbd26Vc8884x27twpSXryySf15ptv6s0339R3332nSZMmae/evZc9Z/ny5TVu3DiNHTtWS5Ys0aFDh5SUlKSFCxdKkkJCQlShQgUlJibq+PHjysrKknTxJufx8fGaM2eOvvvuO+3evVuLFi3SzJkzJUn9+vVTuXLlNGjQIO3bt09r167Vv/71Lyd/QgBwbaKRBOB0NptNa9eu1R133KGHH35Y9evXV58+fXTkyBGFhoZKknr37q1nn31W48aNU/PmzfXjjz/q8ccf/8PzTpw4UaNHj9azzz6rhg0bqnfv3srIyJAkeXt769///rfmz5+viIgI3XXXXZKkRx55RG+88YYSEhLUuHFjtWrVSgkJCebtgipVqqQ1a9Zo3759atq0qSZMmKDp06c78dMBgGuXzWBDEAAAACwgkQQAAIAlNJIAAACwhEYSAAAAltBIAgAAwBIaSQAAAFhCIwkAAABLaCQBAABgCY0kAAAALKGRBAAAgCU0kgAAALCERhIAAACW/C8G2zirJx5c4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test_np, y_pred_np)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b4143-eb2b-4e65-96bb-1bf59b673860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
